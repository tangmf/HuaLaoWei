
# --------------------------------------------------------
# SERVICES
# --------------------------------------------------------

services:
  # --------------------------------------------------------
  # Data Stores
  # --------------------------------------------------------

  minio:
    # Object Storage Service (MinIO)
    container_name: minio
    image: minio/minio
    env_file:
      - .env.dev
    command: server /data --console-address ":9001"
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - hualaowei

  init_os:
    # One-time MinIO Bucket Setup
    container_name: init_os
    image: minio/mc
    depends_on:
      minio:
        condition: service_healthy
    env_file:
      - .env.dev
    volumes:
      - ./data_stores/object_storage:/app/data_stores/object_storage
    entrypoint: ["/bin/bash", "/app/data_stores/object_storage/entrypoint_init_os.sh"]
    restart: "no"
    networks:
      - hualaowei

  postgres:
    # Relational Database
    container_name: postgres
    build:
      context: .
      dockerfile: data_stores/relational_db/Dockerfile.db
    env_file:
      - .env.dev
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "PGPASSWORD=$${POSTGRES_PASSWORD} pg_isready -U $${POSTGRES_USER} -d $${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - hualaowei

  init_db:
    # One-time Database Schema Initializer
    container_name: init_db
    build:
      context: .
      dockerfile: data_stores/relational_db/Dockerfile.init_db
    env_file:
      - .env.dev
    depends_on:
      postgres:
        condition: service_healthy
    volumes:
      - ./data_stores/relational_db:/app/data_stores/relational_db
      - ./config:/app/config
    entrypoint: ["/bin/bash", "/app/data_stores/relational_db/entrypoint_init_db.sh"]
    restart: "no"
    networks:
      - hualaowei

  weaviate:
    container_name: weaviate
    command:
    - --host
    - 0.0.0.0
    - --port
    - '8080'
    - --scheme
    - http
    image: cr.weaviate.io/semitechnologies/weaviate:1.30.4
    ports:
    - 8080:8080
    - 50051:50051
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      ENABLE_API_BASED_MODULES: 'true'
      CLUSTER_HOSTNAME: 'node1'
    volumes:
    - weaviate_data:/var/lib/weaviate
    healthcheck:
      test: ["CMD", "wget", "--tries=3", "--spider", "http://localhost:8080/v1/.well-known/ready"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 60s
    restart: on-failure:0
    networks:
      - hualaowei

  init_vs:
    # One-time Weaviate Schema and Webhook Setup
    container_name: init_vs
    build:
      context: .
      dockerfile: data_stores/vectorstore/Dockerfile.init_vs
    environment:
      PYTHONPATH: /app
    env_file:
      - .env.dev
    depends_on:
      weaviate:
        condition: service_healthy
    volumes:
      - ./data_stores/vectorstore:/app/data_stores/vectorstore
      - ./config:/app/config
    entrypoint: ["/bin/bash", "/app/data_stores/vectorstore/entrypoint_init_vs.sh"]
    ports:
    - "5005:5005"
    restart: "no"
    networks:
      - hualaowei

  # --------------------------------------------------------
  # AI Model Servers
  # --------------------------------------------------------

  chatbot:
    # Chatbot Server (Speech, Translation, RAG)
    container_name: chatbot
    build: 
      context: .
      dockerfile: ai_models/chatbot/Dockerfile
    env_file:
      - .env.dev
    # depends_on:
    #   weaviate:
    #     condition: service_healthy
    ports:
      - "11434:11434"
      - "6001:8100"
    volumes:
      - ollama_data:/root/.ollama
      - ./config:/app/config
      - ./ai_models/chatbot:/app/ai_models/chatbot
    entrypoint: ["/bin/sh", "-c", "./ai_models/chatbot/entrypoint.sh"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8100/health"]
      interval: 30s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - hualaowei

  vlm_issue_categoriser:
    # Visual Language Model for Issue Categorisation
    container_name: vlm_issue_categoriser
    build: 
      context: .
      dockerfile: ai_models/vlm_issue_categoriser/Dockerfile
    env_file:
      - .env.dev
    # depends_on:
    #   weaviate:
    #     condition: service_healthy
    environment:
      - HF_HOME=/app/cache/huggingface
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    ports:
      - "6010:8101"
    volumes:
      - ./config:/app/config
      - ./ai_models/vlm_issue_categoriser:/app/ai_models/vlm_issue_categoriser
      - vlm_hf_cache:/app/cache/huggingface
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8101/health"]
      interval: 30s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - hualaowei

  stfm_issue_count:
    # Forecasting Model for Issue Count Predictions
    container_name: stfm_issue_count
    build: 
      context: .
      dockerfile: ai_models/stfm_issue_count/Dockerfile
    env_file:
      - .env.dev
    ports:
      - "6011:8102"
    volumes:
      - ./config:/app/config
      - ./ai_models/stfm_issue_count:/app/ai_models/stfm_issue_count
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8102/health"]
      interval: 20s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - hualaowei

  # --------------------------------------------------------
  # Unified Backend Server
  # --------------------------------------------------------

  unified_backend:
    # Backend for whole system 
    container_name: unified_backend
    build: 
      context: .
      dockerfile: backend/Dockerfile
    env_file:
      - .env.dev
    ports:
      - "8000:8000"
    volumes:
      - ./config:/app/config
      - ./backend:/app/backend
    # depends_on:
    #   chatbot:
    #     condition: service_healthy
    #   vlm_issue_categoriser:
    #     condition: service_healthy
    restart: unless-stopped
    networks:
      - hualaowei

# --------------------------------------------------------
# Volumes
# --------------------------------------------------------

volumes:
  pgdata:
  weaviate_data:
  ollama_data:
  minio_data:
  vlm_hf_cache:

# --------------------------------------------------------
# Networks
# --------------------------------------------------------

networks:
  hualaowei:
    driver: bridge
