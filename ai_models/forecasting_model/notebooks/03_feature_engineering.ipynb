{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce16ef32",
   "metadata": {},
   "source": [
    "# 3.0 **Installation & Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62d18936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# Load cleaned dataset from previous step\n",
    "df = pd.read_csv(\"./data/cleaned_reports.csv\", parse_dates=[\"reported_datetime\", \"closed_datetime\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b9c3ab",
   "metadata": {},
   "source": [
    "**Encode Time Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b835a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract time encodings\n",
    "df[\"hour\"] = df[\"reported_datetime\"].dt.hour\n",
    "df[\"day_of_week\"] = df[\"reported_datetime\"].dt.dayofweek\n",
    "df[\"month\"] = df[\"reported_datetime\"].dt.month\n",
    "\n",
    "# Cyclical encoding for models like XGBoost or NN\n",
    "df[\"hour_sin\"] = np.sin(2 * np.pi * df[\"hour\"] / 24)\n",
    "df[\"hour_cos\"] = np.cos(2 * np.pi * df[\"hour\"] / 24)\n",
    "df[\"dow_sin\"] = np.sin(2 * np.pi * df[\"day_of_week\"] / 7)\n",
    "df[\"dow_cos\"] = np.cos(2 * np.pi * df[\"day_of_week\"] / 7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2f0faf",
   "metadata": {},
   "source": [
    "**Engineer Time-To-Resolve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eba551c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"resolved_datetime\" in df.columns:\n",
    "    df[\"resolved_datetime\"] = pd.to_datetime(df[\"resolved_datetime\"], errors=\"coerce\")\n",
    "    df[\"time_to_resolve_hours\"] = (df[\"resolved_datetime\"] - df[\"reported_datetime\"]).dt.total_seconds() / 3600\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18f312f",
   "metadata": {},
   "source": [
    "**POI Feature Aggregation â€“ Density & Proximity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ea6b3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check sample of POI columns\n",
    "poi_cols = [col for col in df.columns if \"dist_\" in col or \"count_\" in col]\n",
    "\n",
    "# Normalize POI density features\n",
    "scaler = StandardScaler()\n",
    "df[poi_cols] = scaler.fit_transform(df[poi_cols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601c6c41",
   "metadata": {},
   "source": [
    "**Weather & Air Quality Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0f0c78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify environmental columns\n",
    "env_cols = [\n",
    "    \"temp_c\", \"humidity\", \"wind_kph\", \"precip_mm\",\n",
    "    \"pm10\", \"pm2_5\", \"co\", \"no2\", \"o3\", \"so2\"\n",
    "]\n",
    "\n",
    "# Fill missing values with mean (or use interpolation depending on usage)\n",
    "df[env_cols] = df[env_cols].fillna(df[env_cols].mean())\n",
    "\n",
    "# Optional: Standardize\n",
    "df[env_cols] = scaler.fit_transform(df[env_cols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbccef57",
   "metadata": {},
   "source": [
    "**Socio-Demographics Enrichment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "206e4412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize socio-demographic columns\n",
    "demo_cols = [\"median_income\", \"total_population\", \"average_age\"]  # Adjust names accordingly\n",
    "df[demo_cols] = scaler.fit_transform(df[demo_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "636c83a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'status', 'reported_datetime', 'closed_datetime', 'issue_type',\n",
       "       'latitude', 'longitude', 'city', 'country', 'temp_c', 'humidity',\n",
       "       'wind_kph', 'precip_mm', 'pm10', 'pm2_5', 'co', 'no2', 'o3', 'so2',\n",
       "       'commercial_count_within_200m', 'dist_to_nearest_commericial',\n",
       "       'recreation_count_within_200m', 'dist_to_nearest_recreation',\n",
       "       'facilities_count_within_200m', 'dist_to_nearest_facility',\n",
       "       'transit_count_within_200m', 'dist_to_nearest_transit', 'boundary_name',\n",
       "       'area_km2', 'median_income', 'total_population', 'average_age',\n",
       "       'is_public_holiday', 'issue_type_sg', 'hour', 'day_of_week', 'month',\n",
       "       'hour_sin', 'hour_cos', 'dow_sin', 'dow_cos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3f6fdb",
   "metadata": {},
   "source": [
    "**Final Feature Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c40f93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Add date column\n",
    "df[\"date\"] = df[\"reported_datetime\"].dt.date\n",
    "\n",
    "# Step 2: Define grouping key\n",
    "group_cols = [\"date\", \"boundary_name\"]\n",
    "\n",
    "# Step 3: Aggregate feature columns (mean per boundary per day)\n",
    "feature_cols = (\n",
    "    [\"day_of_week\", \"dow_sin\", \"dow_cos\", \"month\", \"is_public_holiday\"]\n",
    "    + env_cols + poi_cols + demo_cols\n",
    ")\n",
    "df_features = df.groupby(group_cols)[feature_cols].mean().reset_index()\n",
    "\n",
    "# Step 4: Count issue types (pivot)\n",
    "df_targets = df.groupby(group_cols + [\"issue_type_sg\"]).size().unstack(fill_value=0).reset_index()\n",
    "\n",
    "# Step 5: Merge features + targets on date + boundary\n",
    "df_merged = pd.merge(df_features, df_targets, on=group_cols)\n",
    "\n",
    "# Step 6: (Optional) Rename for clarity\n",
    "df_merged = df_merged.rename(columns={\"boundary_name\": \"boundary\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e83ddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_type_columns = df[\"issue_type_sg\"].unique().tolist()\n",
    "issue_type_columns.sort()\n",
    "\n",
    "features_X = df_merged.drop(columns=issue_type_columns)  # All except issue type counts\n",
    "labels_y = df_merged[issue_type_columns]                 # Only issue count columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c755f994",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "features_X.to_csv(\"./data/features_X.csv\", index=False)\n",
    "labels_y.to_csv(\"./data/labels_y.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fa2dfe",
   "metadata": {},
   "source": [
    "Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e48326",
   "metadata": {},
   "source": [
    "### Feature Engineering Summary\n",
    "\n",
    "- **Time-based features**: hour, day of week, cyclical time, public holiday\n",
    "- **Environmental**: temperature, humidity, air pollutants, wind, precipitation\n",
    "- **POIs**: normalized density/proximity by type\n",
    "- **Socio-demographic**: income, age, population\n",
    "- **Optional**: time to resolve (if resolution timestamp exists)\n",
    "\n",
    "Next step: train and evaluate forecasting model using `features_X.csv` and `labels_y.csv`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
