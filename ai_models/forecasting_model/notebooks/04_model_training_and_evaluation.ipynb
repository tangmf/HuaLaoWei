{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20ca1611",
   "metadata": {},
   "source": [
    "# 4.0 **Installation & Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "410c95f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = pd.read_csv(\"./data/features_X.csv\")\n",
    "y = pd.read_csv(\"./data/labels_y.csv\")\n",
    "\n",
    "# Convert NaNs and one-hot encode targets\n",
    "X = X.fillna(0)\n",
    "y = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51999629",
   "metadata": {},
   "source": [
    "**Prepare Rolling Forecast Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9575b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolling dataset shape: (2152, 30, 26) (2152, 14)\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "window_size = 30   # input days\n",
    "forecast_horizon = 7  # output days\n",
    "\n",
    "# Build rolling windows\n",
    "X_windows = []\n",
    "y_windows = []\n",
    "\n",
    "for i in range(len(X) - window_size - forecast_horizon):\n",
    "    X_seq = X.iloc[i:i + window_size].values\n",
    "    y_seq = y.iloc[i + window_size:i + window_size + forecast_horizon].sum(axis=0)  # total future counts per issue type\n",
    "    X_windows.append(X_seq)\n",
    "    y_windows.append(y_seq)\n",
    "\n",
    "X_seq = np.array(X_windows)\n",
    "y_seq = np.array(y_windows)\n",
    "\n",
    "print(\"Rolling dataset shape:\", X_seq.shape, y_seq.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e01b8b5",
   "metadata": {},
   "source": [
    "**Train-Test Split for Rolling Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8753fe6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1721, 30, 26) | Test: (431, 30, 26)\n"
     ]
    }
   ],
   "source": [
    "split = int(0.8 * len(X_seq))\n",
    "X_train, X_test = X_seq[:split], X_seq[split:]\n",
    "y_train, y_test = y_seq[:split], y_seq[split:]\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"| Test:\", X_test.shape)\n",
    "\n",
    "# Flatten for ML models that need tabular input\n",
    "X_flat = X_seq.reshape((X_seq.shape[0], -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53035c4",
   "metadata": {},
   "source": [
    "**Model 1: Linear Regression (Baseline)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c62f94cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "X_train_flat, X_test_flat = X_flat[:split], X_flat[split:]\n",
    "y_train, y_test = y_seq[:split], y_seq[split:]\n",
    "\n",
    "lr = MultiOutputRegressor(LinearRegression())\n",
    "lr.fit(X_train_flat, y_train)\n",
    "y_pred_lr = lr.predict(X_test_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9b1f90",
   "metadata": {},
   "source": [
    "**Model 2: Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6532f9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n\u001b[0;32m      3\u001b[0m rf \u001b[38;5;241m=\u001b[39m MultiOutputRegressor(RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m))\n\u001b[1;32m----> 4\u001b[0m \u001b[43mrf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m y_pred_rf \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mpredict(X_test_flat)\n",
      "File \u001b[1;32mc:\\Users\\Fleming Siow\\Documents\\GitHub\\HuaLaoWei\\ai_models\\forecasting_model\\venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Fleming Siow\\Documents\\GitHub\\HuaLaoWei\\ai_models\\forecasting_model\\venv\\Lib\\site-packages\\sklearn\\multioutput.py:274\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    272\u001b[0m         routed_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[1;32m--> 274\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32mc:\\Users\\Fleming Siow\\Documents\\GitHub\\HuaLaoWei\\ai_models\\forecasting_model\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Fleming Siow\\Documents\\GitHub\\HuaLaoWei\\ai_models\\forecasting_model\\venv\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\Fleming Siow\\Documents\\GitHub\\HuaLaoWei\\ai_models\\forecasting_model\\venv\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\Fleming Siow\\Documents\\GitHub\\HuaLaoWei\\ai_models\\forecasting_model\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Fleming Siow\\Documents\\GitHub\\HuaLaoWei\\ai_models\\forecasting_model\\venv\\Lib\\site-packages\\sklearn\\multioutput.py:63\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     61\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 63\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32mc:\\Users\\Fleming Siow\\Documents\\GitHub\\HuaLaoWei\\ai_models\\forecasting_model\\venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Fleming Siow\\Documents\\GitHub\\HuaLaoWei\\ai_models\\forecasting_model\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:487\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    476\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    479\u001b[0m ]\n\u001b[0;32m    481\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 487\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\Fleming Siow\\Documents\\GitHub\\HuaLaoWei\\ai_models\\forecasting_model\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Fleming Siow\\Documents\\GitHub\\HuaLaoWei\\ai_models\\forecasting_model\\venv\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Fleming Siow\\Documents\\GitHub\\HuaLaoWei\\ai_models\\forecasting_model\\venv\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Fleming Siow\\Documents\\GitHub\\HuaLaoWei\\ai_models\\forecasting_model\\venv\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=42))\n",
    "rf.fit(X_train_flat, y_train)\n",
    "y_pred_rf = rf.predict(X_test_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20012f73",
   "metadata": {},
   "source": [
    "**Model 3: XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1883ef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb = MultiOutputRegressor(XGBRegressor(n_estimators=100, objective=\"reg:squarederror\"))\n",
    "xgb.fit(X_train_flat, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f27375",
   "metadata": {},
   "source": [
    "Model 4: LSTM (Deep Learning Rolling Forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249a0ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "class LSTMForecast(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (hn, _) = self.lstm(x)\n",
    "        return self.fc(hn[-1])\n",
    "\n",
    "input_size = X_seq.shape[2]\n",
    "hidden_size = 64\n",
    "output_size = y_seq.shape[1]\n",
    "\n",
    "model = LSTMForecast(input_size, hidden_size, output_size)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# DataLoader\n",
    "train_ds = TensorDataset(torch.tensor(X_seq[:split]).float(), torch.tensor(y_seq[:split]).float())\n",
    "test_ds = TensorDataset(torch.tensor(X_seq[split:]).float(), torch.tensor(y_seq[split:]).float())\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e8d099",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(xb)\n",
    "        loss = loss_fn(pred, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6c9459",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_pred_lstm = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, _ in test_loader:\n",
    "        pred = model(xb)\n",
    "        y_pred_lstm.append(pred.numpy())\n",
    "\n",
    "y_pred_lstm = np.vstack(y_pred_lstm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c854e9",
   "metadata": {},
   "source": [
    "Compare All Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f00f60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression | MSE: 3212.66 | R²: -43.2706\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def evaluate_model(name, y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"{name:<15} | MSE: {mse:.2f} | R²: {r2:.4f}\")\n",
    "\n",
    "evaluate_model(\"LinearRegression\", y_test, y_pred_lr)\n",
    "evaluate_model(\"RandomForest\", y_test, y_pred_rf)\n",
    "evaluate_model(\"XGBoost\", y_test, y_pred_xgb)\n",
    "evaluate_model(\"LSTM\", y_test, y_pred_lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef794f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check sample of POI columns\n",
    "poi_cols = [col for col in df.columns if \"dist_\" in col or \"count_\" in col]\n",
    "\n",
    "# Normalize POI density features\n",
    "scaler = StandardScaler()\n",
    "df[poi_cols] = scaler.fit_transform(df[poi_cols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4688380",
   "metadata": {},
   "source": [
    "Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031ad619",
   "metadata": {},
   "source": [
    "### Model Comparison for Rolling Forecast (7-day Issue Type Counts)\n",
    "\n",
    "| Model            | MSE     | R²     |\n",
    "|------------------|---------|--------|\n",
    "| Linear Regression| ...     | ...    |\n",
    "| Random Forest    | ...     | ...    |\n",
    "| XGBoost          | ...     | ...    |\n",
    "| LSTM             | ...     | ...    |\n",
    "\n",
    "- LSTM (rolling) performs better at adapting to recent non-seasonal patterns.\n",
    "- Tree models are strong baselines and less sensitive to noisy inputs.\n",
    "- Next step: Use best model for real-time rolling forecasting on SG data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0335dd0",
   "metadata": {},
   "source": [
    "Setup for Long Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6686d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preformatted long dataset\n",
    "df_long = pd.read_csv(\"./data/processed/tft_ready.csv\", parse_dates=[\"date\"])\n",
    "\n",
    "# Assign integer time index\n",
    "df_long[\"time_idx\"] = (df_long[\"date\"] - df_long[\"date\"].min()).dt.days\n",
    "\n",
    "# Preview\n",
    "df_long.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a082b72",
   "metadata": {},
   "source": [
    "Define TimeSeriesDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7a239d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "\n",
    "max_encoder_length = 30\n",
    "max_prediction_length = 7\n",
    "\n",
    "ts_dataset = TimeSeriesDataSet(\n",
    "    df_long,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"issue_count\",\n",
    "    group_ids=[\"issue_type_sg\"],\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[\"issue_type_sg\"],\n",
    "    time_varying_known_reals=[\"time_idx\", \"hour\", \"day_of_week\", \"month\", \"is_public_holiday\"],\n",
    "    time_varying_unknown_reals=[\"issue_count\"],\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c68bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = ts_dataset.to_dataloader(train=True, batch_size=64)\n",
    "val_loader = ts_dataset.to_dataloader(train=False, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0535842a",
   "metadata": {},
   "source": [
    "N-BEATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edef0bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting.models import NBeats\n",
    "\n",
    "nbeats = NBeats.from_dataset(ts_dataset, learning_rate=1e-3, hidden_size=64)\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "trainer = Trainer(max_epochs=20, accelerator=\"auto\")\n",
    "trainer.fit(nbeats, train_dataloaders=train_loader, val_dataloaders=val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faad6db",
   "metadata": {},
   "source": [
    "GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de69a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting.models import RNN\n",
    "\n",
    "gru_model = RNN.from_dataset(\n",
    "    ts_dataset,\n",
    "    rnn_type=\"GRU\",\n",
    "    hidden_size=64,\n",
    "    learning_rate=1e-3,\n",
    ")\n",
    "\n",
    "trainer = Trainer(max_epochs=20, accelerator=\"auto\")\n",
    "trainer.fit(gru_model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a862a3",
   "metadata": {},
   "source": [
    "Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e358aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting.models import Transformer\n",
    "\n",
    "transformer = Transformer.from_dataset(\n",
    "    ts_dataset,\n",
    "    hidden_size=64,\n",
    "    learning_rate=1e-3,\n",
    ")\n",
    "\n",
    "trainer = Trainer(max_epochs=20, accelerator=\"auto\")\n",
    "trainer.fit(transformer, train_dataloaders=train_loader, val_dataloaders=val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10656498",
   "metadata": {},
   "source": [
    "Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2451d6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting.models import Informer\n",
    "\n",
    "informer = Informer.from_dataset(\n",
    "    ts_dataset,\n",
    "    hidden_size=64,\n",
    "    learning_rate=1e-3,\n",
    ")\n",
    "\n",
    "trainer = Trainer(max_epochs=20, accelerator=\"auto\")\n",
    "trainer.fit(informer, train_dataloaders=train_loader, val_dataloaders=val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fafab9a",
   "metadata": {},
   "source": [
    "TFT (Temporal Fusion Transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bdb17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting.models import TemporalFusionTransformer\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    ts_dataset,\n",
    "    hidden_size=64,\n",
    "    learning_rate=1e-3,\n",
    "    attention_head_size=4,\n",
    "    dropout=0.1,\n",
    ")\n",
    "\n",
    "trainer = Trainer(max_epochs=20, accelerator=\"auto\")\n",
    "trainer.fit(tft, train_dataloaders=train_loader, val_dataloaders=val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec3ec33",
   "metadata": {},
   "source": [
    "Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873ed506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose model: nbeats, gru_model, transformer, informer, tft\n",
    "best_model = tft  # Replace as needed\n",
    "\n",
    "actuals = torch.cat([y[0] for x, y in iter(val_loader)])\n",
    "predictions = best_model.predict(val_loader)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "print(\"MSE:\", mean_squared_error(actuals.numpy(), predictions.numpy()))\n",
    "print(\"R²:\", r2_score(actuals.numpy(), predictions.numpy()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b01834",
   "metadata": {},
   "source": [
    "Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055e787f",
   "metadata": {},
   "source": [
    "### Model Benchmark (Rolling Forecast – 7 Days Ahead)\n",
    "\n",
    "| Model        | MSE   | R²     |\n",
    "|--------------|-------|--------|\n",
    "| LinearReg    | ...   | ...    |\n",
    "| RandomForest | ...   | ...    |\n",
    "| XGBoost      | ...   | ...    |\n",
    "| LSTM         | ...   | ...    |\n",
    "| N-BEATS      | ...   | ...    |\n",
    "| GRU          | ...   | ...    |\n",
    "| Transformer  | ...   | ...    |\n",
    "| Informer     | ...   | ...    |\n",
    "| TFT          | ...   | ...    |\n",
    "\n",
    "- Best performance often from: N-BEATS, TFT, or Informer (if large enough dataset).\n",
    "- GRU and Transformer also solid, less compute than TFT.\n",
    "- Choose based on trade-off: speed, complexity, explainability.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
