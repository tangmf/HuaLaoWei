{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c737d69",
   "metadata": {},
   "source": [
    "# 1.0 ‎ **Installation & Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857b8085",
   "metadata": {},
   "source": [
    "In this notebook, we prepare the datasets required for time series forecasting. \\\n",
    "We install essential packages and set up paths for accessing weather, socioeconomic, geospatial, and municipal issue datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7c3137",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --quiet pandas numpy flashtext rapidfuzz openai holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c2f85baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Libraries for Data Engineering\n",
    "from flashtext import KeywordProcessor\n",
    "from rapidfuzz import fuzz\n",
    "from openai import OpenAI\n",
    "import holidays\n",
    "\n",
    "# Display full column width\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ded12e",
   "metadata": {},
   "source": [
    "# 1.1 **Preparing the Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13c2e95",
   "metadata": {},
   "source": [
    "### 1.1.1 **Define Dataset Paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2db3426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to raw datasets\n",
    "DATA_DIR = \"../data/datasets\"\n",
    "\n",
    "# Define countries and their respective cities\n",
    "regions = {\n",
    "    \"us\": [\"newyork\"],\n",
    "    # \"us\": [\"chicago\", \"sanfrancisco\", \"newyork\"],\n",
    "    # \"uk\": [\"london\", \"manchester\"],             \n",
    "    # \"sg\": [\"singapore\"]\n",
    "}\n",
    "\n",
    "# Store all paths in a nested dictionary: datasets[country][city][category]\n",
    "datasets = {}\n",
    "for country, cities in regions.items():\n",
    "    datasets[country] = {}\n",
    "    for city in cities:\n",
    "        city_key = city.lower()\n",
    "        datasets[country][city_key] = {\n",
    "            \"municipal\": os.path.join(DATA_DIR, f\"municipal_reports/{country}\", f\"municipal_{country}_{city_key}_311.csv\"),\n",
    "            \"weather\": os.path.join(DATA_DIR, f\"weather/{country}\", f\"weather_{country}_{city_key}_open-meteo.csv\"),\n",
    "            \"geospatial\": os.path.join(DATA_DIR, f\"geospatial/{country}\", f\"geospatial_{country}_{city_key}.csv\"),\n",
    "            \"socioeconomic\": os.path.join(DATA_DIR, f\"socioeconomic/{country}\", f\"socioeconomic_{country}_{city_key}.csv\"),\n",
    "            \"boundaries\": os.path.join(DATA_DIR, f\"boundaries/{country}\", f\"boundaries_{country}_{city_key}.csv\"),\n",
    "            \"clusters\": os.path.join(DATA_DIR, f\"clusters/{country}\", f\"clusters_{country}_{city_key}.csv\"),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d6cb35",
   "metadata": {},
   "source": [
    "### 1.1.2 **Load Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fa517d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../data/datasets/municipal_reports/us/municipal_us_newyork_311.csv\n",
      "Loading ../data/datasets/weather/us/weather_us_newyork_open-meteo.csv\n",
      "Loading ../data/datasets/geospatial/us/geospatial_us_newyork.csv\n",
      "Loading ../data/datasets/socioeconomic/us/socioeconomic_us_newyork.csv\n",
      "Loading ../data/datasets/boundaries/us/boundaries_us_newyork.csv\n",
      "Loading ../data/datasets/clusters/us/clusters_us_newyork.csv\n"
     ]
    }
   ],
   "source": [
    "city_dfs = {}\n",
    "\n",
    "for country in datasets:\n",
    "    city_dfs[country] = {}\n",
    "    for city in datasets[country]:\n",
    "        city_dfs[country][city] = {}\n",
    "        for category in datasets[country][city]:\n",
    "            path = datasets[country][city][category].replace(\"\\\\\", \"/\")\n",
    "            if os.path.exists(path):\n",
    "                print(f\"Loading {path}\")\n",
    "                city_dfs[country][city][category] = pd.read_csv(path, low_memory=False)\n",
    "            else:\n",
    "                print(f\"File not found: {path}\")\n",
    "                city_dfs[country][city][category] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46fe46e",
   "metadata": {},
   "source": [
    "# 1.2 **Understanding the Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8c97da",
   "metadata": {},
   "source": [
    "### 1.2.1 **Municipal Issues Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad6ccf7",
   "metadata": {},
   "source": [
    "**Basic Structure and Dimensions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9f8445c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US | Newyork Municipal Shape: (881879, 41)\n"
     ]
    }
   ],
   "source": [
    "for country in city_dfs:\n",
    "    for city in city_dfs[country]:\n",
    "        df = city_dfs[country][city].get(\"municipal\")\n",
    "        if df is not None:\n",
    "            print(f\"{country.upper()} | {city.capitalize()} Municipal Shape: {df.shape}\")\n",
    "        else:\n",
    "            print(f\"{country.upper()} | {city.capitalize()} Municipal: Data not loaded or missing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d33813",
   "metadata": {},
   "source": [
    "**Columns, Data Types and Non-Null Overview**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b6688ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "US | Newyork Municipal Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 881879 entries, 0 to 881878\n",
      "Data columns (total 41 columns):\n",
      " #   Column                          Non-Null Count   Dtype  \n",
      "---  ------                          --------------   -----  \n",
      " 0   unique_key                      881879 non-null  int64  \n",
      " 1   created_date                    881879 non-null  object \n",
      " 2   closed_date                     826396 non-null  object \n",
      " 3   agency                          881879 non-null  object \n",
      " 4   agency_name                     881879 non-null  object \n",
      " 5   complaint_type                  881879 non-null  object \n",
      " 6   descriptor                      865096 non-null  object \n",
      " 7   location_type                   786899 non-null  object \n",
      " 8   incident_zip                    878971 non-null  float64\n",
      " 9   incident_address                853217 non-null  object \n",
      " 10  street_name                     853198 non-null  object \n",
      " 11  cross_street_1                  575509 non-null  object \n",
      " 12  cross_street_2                  575738 non-null  object \n",
      " 13  intersection_street_1           550453 non-null  object \n",
      " 14  intersection_street_2           550827 non-null  object \n",
      " 15  address_type                    880162 non-null  object \n",
      " 16  city                            858006 non-null  object \n",
      " 17  landmark                        500327 non-null  object \n",
      " 18  status                          881879 non-null  object \n",
      " 19  resolution_description          858916 non-null  object \n",
      " 20  resolution_action_updated_date  866383 non-null  object \n",
      " 21  community_board                 881879 non-null  object \n",
      " 22  bbl                             810659 non-null  float64\n",
      " 23  borough                         881879 non-null  object \n",
      " 24  x_coordinate_state_plane        881879 non-null  int64  \n",
      " 25  y_coordinate_state_plane        881879 non-null  int64  \n",
      " 26  open_data_channel_type          881879 non-null  object \n",
      " 27  park_facility_name              881269 non-null  object \n",
      " 28  park_borough                    881879 non-null  object \n",
      " 29  latitude                        881879 non-null  float64\n",
      " 30  longitude                       881879 non-null  float64\n",
      " 31  location                        881879 non-null  object \n",
      " 32  vehicle_type                    34311 non-null   object \n",
      " 33  taxi_company_borough            493 non-null     object \n",
      " 34  taxi_pick_up_location           7955 non-null    object \n",
      " 35  facility_type                   2918 non-null    object \n",
      " 36  due_date                        4206 non-null    object \n",
      " 37  bridge_highway_name             2972 non-null    object \n",
      " 38  bridge_highway_segment          2970 non-null    object \n",
      " 39  bridge_highway_direction        980 non-null     object \n",
      " 40  road_ramp                       603 non-null     object \n",
      "dtypes: float64(4), int64(3), object(34)\n",
      "memory usage: 275.9+ MB\n"
     ]
    }
   ],
   "source": [
    "for country in city_dfs:\n",
    "    for city in city_dfs[country]:\n",
    "        df = city_dfs[country][city].get(\"municipal\")\n",
    "        print(f\"\\n{country.upper()} | {city.capitalize()} Municipal Info:\")\n",
    "        if df is not None:\n",
    "            df.info()\n",
    "        else:\n",
    "            print(\"Data not loaded or missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6872c9aa",
   "metadata": {},
   "source": [
    "**Summary of Key Stats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ead037d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "US | Newyork Municipal Describe:\n",
      "          unique_key             created_date              closed_date  agency                      agency_name   complaint_type        descriptor  \\\n",
      "count   8.818790e+05                   881879                   826396  881879                           881879           881879            865096   \n",
      "unique           NaN                   729284                   540597      15                               15              171               803   \n",
      "top              NaN  2025-03-03T07:00:00.000  2025-03-04T00:00:00.000    NYPD  New York City Police Department  Illegal Parking  Loud Music/Party   \n",
      "freq             NaN                       31                      409  389877                           389877           140106            107373   \n",
      "mean    6.405509e+07                      NaN                      NaN     NaN                              NaN              NaN               NaN   \n",
      "std     2.741836e+05                      NaN                      NaN     NaN                              NaN              NaN               NaN   \n",
      "min     6.357209e+07                      NaN                      NaN     NaN                              NaN              NaN               NaN   \n",
      "25%     6.381624e+07                      NaN                      NaN     NaN                              NaN              NaN               NaN   \n",
      "50%     6.405430e+07                      NaN                      NaN     NaN                              NaN              NaN               NaN   \n",
      "75%     6.429303e+07                      NaN                      NaN     NaN                              NaN              NaN               NaN   \n",
      "max     6.458127e+07                      NaN                      NaN     NaN                              NaN              NaN               NaN   \n",
      "\n",
      "               location_type   incident_zip      incident_address       street_name    cross_street_1 cross_street_2 intersection_street_1  \\\n",
      "count                 786899  878971.000000                853217            853198            575509         575738                550453   \n",
      "unique                   124            NaN                218078              8496             12298          12430                  8008   \n",
      "top     RESIDENTIAL BUILDING            NaN  655 EAST  230 STREET  EAST  230 STREET  CARPENTER AVENUE  LOWERRE PLACE      CARPENTER AVENUE   \n",
      "freq                  249017            NaN                 47013             52858             52801          52434                 52767   \n",
      "mean                     NaN   10798.480044                   NaN               NaN               NaN            NaN                   NaN   \n",
      "std                      NaN     525.253791                   NaN               NaN               NaN            NaN                   NaN   \n",
      "min                      NaN      83.000000                   NaN               NaN               NaN            NaN                   NaN   \n",
      "25%                      NaN   10453.000000                   NaN               NaN               NaN            NaN                   NaN   \n",
      "50%                      NaN   11103.000000                   NaN               NaN               NaN            NaN                   NaN   \n",
      "75%                      NaN   11231.000000                   NaN               NaN               NaN            NaN                   NaN   \n",
      "max                      NaN   12345.000000                   NaN               NaN               NaN            NaN                   NaN   \n",
      "\n",
      "       intersection_street_2 address_type      city          landmark  status                             resolution_description  \\\n",
      "count                 550827       880162    858006            500327  881879                                             858916   \n",
      "unique                  8244            5        54              6956       7                                                584   \n",
      "top            LOWERRE PLACE      ADDRESS  BROOKLYN  EAST  230 STREET  Closed  The Police Department responded to the complai...   \n",
      "freq                   52431       825622    253335             52667  821464                                             127984   \n",
      "mean                     NaN          NaN       NaN               NaN     NaN                                                NaN   \n",
      "std                      NaN          NaN       NaN               NaN     NaN                                                NaN   \n",
      "min                      NaN          NaN       NaN               NaN     NaN                                                NaN   \n",
      "25%                      NaN          NaN       NaN               NaN     NaN                                                NaN   \n",
      "50%                      NaN          NaN       NaN               NaN     NaN                                                NaN   \n",
      "75%                      NaN          NaN       NaN               NaN     NaN                                                NaN   \n",
      "max                      NaN          NaN       NaN               NaN     NaN                                                NaN   \n",
      "\n",
      "       resolution_action_updated_date community_board           bbl   borough  x_coordinate_state_plane  y_coordinate_state_plane  \\\n",
      "count                          866383          881879  8.106590e+05    881879              8.818790e+05             881879.000000   \n",
      "unique                         473553              77           NaN         6                       NaN                       NaN   \n",
      "top           2025-01-22T00:00:00.000        12 BRONX           NaN  BROOKLYN                       NaN                       NaN   \n",
      "freq                             5491           72711           NaN    259993                       NaN                       NaN   \n",
      "mean                              NaN             NaN  2.663000e+09       NaN              1.006730e+06             211188.617576   \n",
      "std                               NaN             NaN  1.120658e+09       NaN              2.046305e+04              33272.814645   \n",
      "min                               NaN             NaN  0.000000e+00       NaN              9.135270e+05             121152.000000   \n",
      "25%                               NaN             NaN  2.028660e+09       NaN              9.949610e+05             185586.000000   \n",
      "50%                               NaN             NaN  3.011378e+09       NaN              1.006187e+06             208446.000000   \n",
      "75%                               NaN             NaN  3.086770e+09       NaN              1.021411e+06             241884.000000   \n",
      "max                               NaN             NaN  5.270001e+09       NaN              1.067186e+06             271876.000000   \n",
      "\n",
      "       open_data_channel_type park_facility_name park_borough       latitude      longitude                                           location  \\\n",
      "count                  881879             881269       881879  881879.000000  881879.000000                                             881879   \n",
      "unique                      4                586            6            NaN            NaN                                             229101   \n",
      "top                    ONLINE        Unspecified     BROOKLYN            NaN            NaN  {'latitude': '40.89187241649303', 'longitude':...   \n",
      "freq                   371050             879252       259993            NaN            NaN                                              47013   \n",
      "mean                      NaN                NaN          NaN      40.746288     -73.918829                                                NaN   \n",
      "std                       NaN                NaN          NaN       0.091322       0.073821                                                NaN   \n",
      "min                       NaN                NaN          NaN      40.498949     -74.254326                                                NaN   \n",
      "25%                       NaN                NaN          NaN      40.676031     -73.961381                                                NaN   \n",
      "50%                       NaN                NaN          NaN      40.738747     -73.920824                                                NaN   \n",
      "75%                       NaN                NaN          NaN      40.830543     -73.865851                                                NaN   \n",
      "max                       NaN                NaN          NaN      40.912869     -73.700715                                                NaN   \n",
      "\n",
      "       vehicle_type taxi_company_borough                              taxi_pick_up_location facility_type                 due_date  \\\n",
      "count         34311                  493                                               7955          2918                     4206   \n",
      "unique            9                    5                                               5166             1                     2652   \n",
      "top             Car            MANHATTAN  JOHN F KENNEDY AIRPORT, QUEENS (JAMAICA) ,NY, ...   DSNY Garage  2025-01-18T05:49:24.000   \n",
      "freq          22093                  143                                                665          2918                       81   \n",
      "mean            NaN                  NaN                                                NaN           NaN                      NaN   \n",
      "std             NaN                  NaN                                                NaN           NaN                      NaN   \n",
      "min             NaN                  NaN                                                NaN           NaN                      NaN   \n",
      "25%             NaN                  NaN                                                NaN           NaN                      NaN   \n",
      "50%             NaN                  NaN                                                NaN           NaN                      NaN   \n",
      "75%             NaN                  NaN                                                NaN           NaN                      NaN   \n",
      "max             NaN                  NaN                                                NaN           NaN                      NaN   \n",
      "\n",
      "       bridge_highway_name bridge_highway_segment bridge_highway_direction road_ramp  \n",
      "count                 2972                   2970                      980       603  \n",
      "unique                  45                     95                      148       165  \n",
      "top                      F               Platform               1 Downtown   Roadway  \n",
      "freq                   364                   1138                       70        90  \n",
      "mean                   NaN                    NaN                      NaN       NaN  \n",
      "std                    NaN                    NaN                      NaN       NaN  \n",
      "min                    NaN                    NaN                      NaN       NaN  \n",
      "25%                    NaN                    NaN                      NaN       NaN  \n",
      "50%                    NaN                    NaN                      NaN       NaN  \n",
      "75%                    NaN                    NaN                      NaN       NaN  \n",
      "max                    NaN                    NaN                      NaN       NaN  \n"
     ]
    }
   ],
   "source": [
    "for country in city_dfs:\n",
    "    for city in city_dfs[country]:\n",
    "        df = city_dfs[country][city].get(\"municipal\")\n",
    "        if df is not None:\n",
    "            print(f\"\\n{country.upper()} | {city.capitalize()} Municipal Describe:\")\n",
    "            print(df.describe(include='all'))\n",
    "        else:\n",
    "            print(f\"\\n{country.upper()} | {city.capitalize()} Municipal: Data not loaded or missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4c1e4f",
   "metadata": {},
   "source": [
    "**Issue Type Diversity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ed67b1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US | Newyork Issue Types (complaint_type):\n",
      "complaint_type\n",
      "Illegal Parking                   140106\n",
      "HEAT/HOT WATER                    134939\n",
      "Noise - Residential               127225\n",
      "Blocked Driveway                   41726\n",
      "UNSANITARY CONDITION               26249\n",
      "PLUMBING                           19018\n",
      "Abandoned Vehicle                  16691\n",
      "Noise - Street/Sidewalk            16111\n",
      "Water System                       15815\n",
      "PAINT/PLASTER                      14901\n",
      "Noise - Commercial                 13989\n",
      "Traffic Signal Condition           13818\n",
      "Street Condition                   13451\n",
      "Noise                              13121\n",
      "Dirty Condition                    12654\n",
      "DOOR/WINDOW                        12195\n",
      "Derelict Vehicles                   9945\n",
      "WATER LEAK                          9721\n",
      "Missed Collection                   8831\n",
      "Illegal Dumping                     8426\n",
      "GENERAL                             8224\n",
      "Snow or Ice                         7873\n",
      "ELECTRIC                            7867\n",
      "General Construction/Plumbing       7846\n",
      "Encampment                          7664\n",
      "Street Light Condition              7257\n",
      "Rodent                              7230\n",
      "Noise - Vehicle                     6787\n",
      "FLOORING/STAIRS                     6689\n",
      "Drug Activity                       5634\n",
      "APPLIANCE                           5292\n",
      "Noise - Helicopter                  5270\n",
      "Sidewalk Condition                  5150\n",
      "Sewer                               5103\n",
      "Homeless Person Assistance          5034\n",
      "Non-Emergency Police Matter         4911\n",
      "Elevator                            4791\n",
      "Graffiti                            4730\n",
      "Vendor Enforcement                  4660\n",
      "Building/Use                        4413\n",
      "For Hire Vehicle Complaint          4351\n",
      "Obstruction                         3956\n",
      "Damaged Tree                        3894\n",
      "Consumer Complaint                  3859\n",
      "Lead                                3708\n",
      "Residential Disposal Complaint      3611\n",
      "SAFETY                              3342\n",
      "Maintenance or Facility             3034\n",
      "Food Establishment                  2892\n",
      "Traffic                             2844\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Map (country, city) to relevant column for issue type\n",
    "issue_type_columns = {\n",
    "    (\"us\", \"chicago\"): \"sr_type\",\n",
    "    (\"us\", \"sanfrancisco\"): \"service_name\",\n",
    "    (\"us\", \"newyork\"): \"complaint_type\",\n",
    "}\n",
    "\n",
    "for country in city_dfs:\n",
    "    for city in city_dfs[country]:\n",
    "        df = city_dfs[country][city].get(\"municipal\")\n",
    "        column = issue_type_columns.get((country, city))\n",
    "        \n",
    "        if df is not None and column in df.columns:\n",
    "            print(f\"{country.upper()} | {city.capitalize()} Issue Types ({column}):\")\n",
    "            print(df[column].value_counts().head(50), \"\\n\")\n",
    "        elif df is not None:\n",
    "            print(f\"{country.upper()} | {city.capitalize()}: Column '{column}' not found in DataFrame.\\n\")\n",
    "        else:\n",
    "            print(f\"{country.upper()} | {city.capitalize()}: Municipal DataFrame not loaded.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79a99aa",
   "metadata": {},
   "source": [
    "**Date Range Checks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "19d75590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US | Newyork Date Range: 2025-01-01 to 2025-04-01\n"
     ]
    }
   ],
   "source": [
    "# Define city-specific date columns\n",
    "date_columns = {\n",
    "    (\"us\", \"chicago\"): \"created_date\",\n",
    "    (\"us\", \"sanfrancisco\"): \"requested_datetime\",\n",
    "    (\"us\", \"newyork\"): \"created_date\",\n",
    "}\n",
    "\n",
    "# Loop through city DataFrames and print date ranges\n",
    "for country in city_dfs:\n",
    "    for city in city_dfs[country]:\n",
    "        df = city_dfs[country][city].get(\"municipal\")\n",
    "        if df is not None:\n",
    "            date_col = date_columns.get((country, city))\n",
    "            \n",
    "            if date_col in df.columns:\n",
    "                try:\n",
    "                    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "                    min_date = df[date_col].min()\n",
    "                    max_date = df[date_col].max()\n",
    "                    print(f\"{country.upper()} | {city.capitalize()} Date Range: {min_date.date()} to {max_date.date()}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"{country.upper()} | {city.capitalize()} Date Range: Error parsing dates – {str(e)}\")\n",
    "            else:\n",
    "                print(f\"{country.upper()} | {city.capitalize()}: Date column '{date_col}' not found in DataFrame\")\n",
    "        else:\n",
    "            print(f\"{country.upper()} | {city.capitalize()} Municipal: Data not loaded or missing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1c0fa0",
   "metadata": {},
   "source": [
    "### 1.2.2 **Weather Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac375f7",
   "metadata": {},
   "source": [
    "**Basic Structure and Dimensions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d76f9f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US | Newyork Weather Shape: (226619, 15)\n"
     ]
    }
   ],
   "source": [
    "for country in city_dfs:\n",
    "    for city in city_dfs[country]:\n",
    "        df = city_dfs[country][city].get(\"weather\")\n",
    "        if df is not None:\n",
    "            print(f\"{country.upper()} | {city.capitalize()} Weather Shape: {df.shape}\")\n",
    "        else:\n",
    "            print(f\"{country.upper()} | {city.capitalize()} Weather: Data not loaded or missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae2202f",
   "metadata": {},
   "source": [
    "**Columns, Data Types and Non-Null Overview**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ed50dc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "US | Newyork Weather Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 226619 entries, 0 to 226618\n",
      "Data columns (total 15 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   report_id             226619 non-null  int64  \n",
      " 1   latitude              226619 non-null  float64\n",
      " 2   longitude             226619 non-null  float64\n",
      " 3   reported_datetime     226619 non-null  object \n",
      " 4   weather_datetime      226619 non-null  object \n",
      " 5   temperature_2m        226619 non-null  float64\n",
      " 6   relative_humidity_2m  226619 non-null  int64  \n",
      " 7   precipitation         226619 non-null  float64\n",
      " 8   windspeed_10m         226619 non-null  float64\n",
      " 9   pm10                  226619 non-null  float64\n",
      " 10  pm2_5                 226619 non-null  float64\n",
      " 11  carbon_monoxide       226619 non-null  int64  \n",
      " 12  nitrogen_dioxide      226619 non-null  float64\n",
      " 13  ozone                 226619 non-null  int64  \n",
      " 14  sulphur_dioxide       226619 non-null  float64\n",
      "dtypes: float64(9), int64(4), object(2)\n",
      "memory usage: 25.9+ MB\n"
     ]
    }
   ],
   "source": [
    "for country in city_dfs:\n",
    "    for city in city_dfs[country]:\n",
    "        df = city_dfs[country][city].get(\"weather\")\n",
    "        print(f\"\\n{country.upper()} | {city.capitalize()} Weather Info:\")\n",
    "        if df is not None:\n",
    "            df.info()\n",
    "        else:\n",
    "            print(\"Data not loaded or missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b094a18d",
   "metadata": {},
   "source": [
    "**Viewing the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "14f0000e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US | Newyork Weather First 3 Rows:\n",
      "   report_id   latitude  longitude        reported_datetime weather_datetime  temperature_2m  relative_humidity_2m  precipitation  windspeed_10m  \\\n",
      "0   64526404  40.844482  -73.89044  2025-04-01T23:47:26.000    1/4/2025 2:00            14.4                    98            3.7            8.6   \n",
      "1   64526404  40.844482  -73.89044  2025-04-01T23:47:26.000    1/4/2025 3:00            14.2                    98            4.0            9.3   \n",
      "2   64526404  40.844482  -73.89044  2025-04-01T23:47:26.000    1/4/2025 4:00            14.9                    97            2.4            9.4   \n",
      "\n",
      "   pm10  pm2_5  carbon_monoxide  nitrogen_dioxide  ozone  sulphur_dioxide  \n",
      "0  17.3   16.9              390              72.4     11              6.4  \n",
      "1  20.1   19.9              375              71.3     10              6.6  \n",
      "2  22.5   22.3              330              58.6     20              6.2  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for country in city_dfs:\n",
    "    for city in city_dfs[country]:\n",
    "        df = city_dfs[country][city].get(\"weather\")\n",
    "        print(f\"{country.upper()} | {city.capitalize()} Weather First 3 Rows:\")\n",
    "        if df is not None:\n",
    "            print(df.head(3))\n",
    "        else:\n",
    "            print(\"Data not loaded or missing.\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ee1eda",
   "metadata": {},
   "source": [
    "**Summary of Key Stats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "613ed9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "US | Newyork Weather Describe (Selected Columns):\n",
      "       temperature_2m  relative_humidity_2m  precipitation  windspeed_10m           pm10          pm2_5  carbon_monoxide  nitrogen_dioxide  \\\n",
      "count   226619.000000         226619.000000  226619.000000  226619.000000  226619.000000  226619.000000    226619.000000     226619.000000   \n",
      "mean        13.286737             82.158654       1.104199      13.668010      11.141519      10.558537       243.054576         27.900215   \n",
      "std          4.770037             16.001017       1.749093       5.562395       5.887698       5.689661        57.197623         20.864907   \n",
      "min          3.400000             36.000000       0.000000       1.300000       0.800000       0.800000       145.000000          2.400000   \n",
      "25%          9.100000             73.000000       0.000000       8.800000       7.500000       6.700000       211.000000          9.700000   \n",
      "50%         14.200000             87.000000       0.100000      13.800000      10.900000      10.300000       229.000000         19.700000   \n",
      "75%         16.600000             94.000000       2.100000      18.300000      15.300000      14.600000       255.000000         39.700000   \n",
      "max         25.300000            100.000000      14.400000      40.500000      23.600000      23.300000       518.000000         72.400000   \n",
      "\n",
      "               ozone  sulphur_dioxide  \n",
      "count  226619.000000    226619.000000  \n",
      "mean       57.443096         4.108039  \n",
      "std        23.889965         1.674336  \n",
      "min        10.000000         0.100000  \n",
      "25%        40.000000         2.500000  \n",
      "50%        62.000000         4.300000  \n",
      "75%        75.000000         5.600000  \n",
      "max       109.000000         6.600000  \n"
     ]
    }
   ],
   "source": [
    "columns_to_describe = [\"temperature_2m\", \"relative_humidity_2m\", \"precipitation\", \"windspeed_10m\", \"pm10\", \"pm2_5\", \"carbon_monoxide\", \"nitrogen_dioxide\", \"ozone\", \"sulphur_dioxide\"]\n",
    "for country in city_dfs:\n",
    "    for city in city_dfs[country]:\n",
    "        df = city_dfs[country][city].get(\"weather\")\n",
    "        if df is not None:\n",
    "            cols = [col for col in columns_to_describe if col in df.columns]\n",
    "            if cols:\n",
    "                print(f\"\\n{country.upper()} | {city.capitalize()} Weather Describe (Selected Columns):\")\n",
    "                print(df[cols].describe(include='all'))\n",
    "            else:\n",
    "                print(f\"\\n{country.upper()} | {city.capitalize()} Weather: None of the selected columns found\")\n",
    "        else:\n",
    "            print(f\"\\n{country.upper()} | {city.capitalize()} Weather: Data not loaded or missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f0a784",
   "metadata": {},
   "source": [
    "### 1.2.3 **Geospatial Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdef25c7",
   "metadata": {},
   "source": [
    "**Basic Structure and Dimensions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "016251e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US | Newyork Geospatial Shape: (881879, 13)\n"
     ]
    }
   ],
   "source": [
    "for country in city_dfs:\n",
    "    for city in city_dfs[country]:\n",
    "        df = city_dfs[country][city].get(\"geospatial\")\n",
    "        if df is not None:\n",
    "            print(f\"{country.upper()} | {city.capitalize()} Geospatial Shape: {df.shape}\")\n",
    "        else:\n",
    "            print(f\"{country.upper()} | {city.capitalize()} Geospatial: Data not loaded or missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1046a6f",
   "metadata": {},
   "source": [
    "**Columns, Data Types and Non-Null Overview**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "33b367b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "US | Newyork Geospatial Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 881879 entries, 0 to 881878\n",
      "Data columns (total 13 columns):\n",
      " #   Column                            Non-Null Count   Dtype  \n",
      "---  ------                            --------------   -----  \n",
      " 0   report_id                         881879 non-null  int64  \n",
      " 1   latitude                          881879 non-null  float64\n",
      " 2   longitude                         881879 non-null  float64\n",
      " 3   commercial_count_within_200m      881879 non-null  int64  \n",
      " 4   dist_to_nearest_commercial_in_m   881879 non-null  float64\n",
      " 5   residential_count_within_200m     881879 non-null  int64  \n",
      " 6   dist_to_nearest_residential_in_m  881879 non-null  float64\n",
      " 7   facilities_count_within_200m      881879 non-null  int64  \n",
      " 8   dist_to_nearest_facilities_in_m   881879 non-null  float64\n",
      " 9   recreation_count_within_200m      881879 non-null  int64  \n",
      " 10  dist_to_nearest_recreation_in_m   881879 non-null  float64\n",
      " 11  transit_count_within_200m         881879 non-null  int64  \n",
      " 12  dist_to_nearest_transit_in_m      881879 non-null  float64\n",
      "dtypes: float64(7), int64(6)\n",
      "memory usage: 87.5 MB\n"
     ]
    }
   ],
   "source": [
    "for country in city_dfs:\n",
    "    for city in city_dfs[country]:\n",
    "        df = city_dfs[country][city].get(\"geospatial\")\n",
    "        print(f\"\\n{country.upper()} | {city.capitalize()} Geospatial Info:\")\n",
    "        if df is not None:\n",
    "            df.info()\n",
    "        else:\n",
    "            print(\"Data not loaded or missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce9b842",
   "metadata": {},
   "source": [
    "**Viewing the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4112ccb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US | Newyork Geospatial First 3 Rows:\n",
      "   report_id   latitude  longitude  commercial_count_within_200m  dist_to_nearest_commercial_in_m  residential_count_within_200m  \\\n",
      "0   64526847  40.592989 -73.784356                             1                        58.941575                              1   \n",
      "1   64525572  40.691837 -73.926142                            11                        17.396196                             21   \n",
      "2   64525039  40.814843 -73.900012                             0                       360.861254                              0   \n",
      "\n",
      "   dist_to_nearest_residential_in_m  facilities_count_within_200m  dist_to_nearest_facilities_in_m  recreation_count_within_200m  \\\n",
      "0                        149.001010                             0                       325.290183                             1   \n",
      "1                         31.604263                             0                       354.273924                             3   \n",
      "2                        679.911540                             1                       130.644037                             2   \n",
      "\n",
      "   dist_to_nearest_recreation_in_m  transit_count_within_200m  dist_to_nearest_transit_in_m  \n",
      "0                        94.413283                          0                    275.802477  \n",
      "1                       123.364664                          3                     41.018689  \n",
      "2                       167.224097                          0                    222.949098  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for country in city_dfs:\n",
    "    for city in city_dfs[country]:\n",
    "        df = city_dfs[country][city].get(\"geospatial\")\n",
    "        print(f\"{country.upper()} | {city.capitalize()} Geospatial First 3 Rows:\")\n",
    "        if df is not None:\n",
    "            print(df.head(3))\n",
    "        else:\n",
    "            print(\"Data not loaded or missing.\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34007432",
   "metadata": {},
   "source": [
    "**Summary of Key Stats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "becc266e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "US | Newyork Geospatial Describe (Selected Columns):\n",
      "       commercial_count_within_200m  dist_to_nearest_commercial_in_m  residential_count_within_200m  dist_to_nearest_residential_in_m  \\\n",
      "count                 881879.000000                    881879.000000                  881879.000000                     881879.000000   \n",
      "mean                       5.319627                       227.489792                       5.726629                        360.550419   \n",
      "std                        9.627804                       219.401600                      15.824878                        383.847987   \n",
      "min                        0.000000                         1.360689                       0.000000                          0.907247   \n",
      "25%                        0.000000                        76.374871                       0.000000                         79.184939   \n",
      "50%                        1.000000                       173.496892                       0.000000                        201.649339   \n",
      "75%                        6.000000                       302.521745                       5.000000                        557.101857   \n",
      "max                      127.000000                      4124.545396                     229.000000                       4023.072744   \n",
      "\n",
      "       facilities_count_within_200m  dist_to_nearest_facilities_in_m  recreation_count_within_200m  dist_to_nearest_recreation_in_m  \\\n",
      "count                 881879.000000                    881879.000000                 881879.000000                    881879.000000   \n",
      "mean                       0.320150                       362.958700                      0.875401                       321.094742   \n",
      "std                        0.694232                       244.679906                      2.040201                       217.845767   \n",
      "min                        0.000000                         4.230528                      0.000000                         0.051205   \n",
      "25%                        0.000000                       208.721183                      0.000000                       153.707080   \n",
      "50%                        0.000000                       298.987298                      0.000000                       269.648262   \n",
      "75%                        0.000000                       468.510687                      1.000000                       455.499827   \n",
      "max                        9.000000                      4222.559839                     57.000000                      2397.121769   \n",
      "\n",
      "       transit_count_within_200m  dist_to_nearest_transit_in_m  \n",
      "count              881879.000000                 881879.000000  \n",
      "mean                    3.922607                    171.882408  \n",
      "std                     5.333649                    134.675976  \n",
      "min                     0.000000                      0.071529  \n",
      "25%                     0.000000                     77.755325  \n",
      "50%                     2.000000                    140.586651  \n",
      "75%                     6.000000                    244.668129  \n",
      "max                    79.000000                   3941.149381  \n"
     ]
    }
   ],
   "source": [
    "columns_to_describe = [\"commercial_count_within_200m\", \"dist_to_nearest_commercial_in_m\", \"residential_count_within_200m\", \"dist_to_nearest_residential_in_m\", \"facilities_count_within_200m\", \"dist_to_nearest_facilities_in_m\", \"recreation_count_within_200m\", \"dist_to_nearest_recreation_in_m\", \"transit_count_within_200m\", \"dist_to_nearest_transit_in_m\"]\n",
    "for country in city_dfs:\n",
    "    for city in city_dfs[country]:\n",
    "        df = city_dfs[country][city].get(\"geospatial\")\n",
    "        if df is not None:\n",
    "            cols = [col for col in columns_to_describe if col in df.columns]\n",
    "            if cols:\n",
    "                print(f\"\\n{country.upper()} | {city.capitalize()} Geospatial Describe (Selected Columns):\")\n",
    "                print(df[cols].describe(include='all'))\n",
    "            else:\n",
    "                print(f\"\\n{country.upper()} | {city.capitalize()} Geospatial: None of the selected columns found\")\n",
    "        else:\n",
    "            print(f\"\\n{country.upper()} | {city.capitalize()} Geospatial: Data not loaded or missing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3862bd51",
   "metadata": {},
   "source": [
    "### 1.2.4 **Socioeconomic Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450e6c9f",
   "metadata": {},
   "source": [
    "**Basic Structure and Dimensions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "916cc148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US | Newyork Socioeconomic Shape: (881846, 7)\n"
     ]
    }
   ],
   "source": [
    "for country in city_dfs:\n",
    "    for city in city_dfs[country]:\n",
    "        df = city_dfs[country][city].get(\"socioeconomic\")\n",
    "        if df is not None:\n",
    "            print(f\"{country.upper()} | {city.capitalize()} Socioeconomic Shape: {df.shape}\")\n",
    "        else:\n",
    "            print(f\"{country.upper()} | {city.capitalize()} Socioeconomic: Data not loaded or missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d77073",
   "metadata": {},
   "source": [
    "**Columns, Data Types and Non-Null Overview**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c5f26fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "US | Newyork Socioeconomic Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 881846 entries, 0 to 881845\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   report_id            881846 non-null  int64  \n",
      " 1   reported_datetime    881846 non-null  object \n",
      " 2   GEOID                881846 non-null  int64  \n",
      " 3   reported_datetime.1  881846 non-null  object \n",
      " 4   median_income        869392 non-null  float64\n",
      " 5   total_population     881846 non-null  float64\n",
      " 6   average_age          875311 non-null  float64\n",
      "dtypes: float64(3), int64(2), object(2)\n",
      "memory usage: 47.1+ MB\n"
     ]
    }
   ],
   "source": [
    "for country in city_dfs:\n",
    "    for city in city_dfs[country]:\n",
    "        df = city_dfs[country][city].get(\"socioeconomic\")\n",
    "        print(f\"\\n{country.upper()} | {city.capitalize()} Socioeconomic Info:\")\n",
    "        if df is not None:\n",
    "            df.info()\n",
    "        else:\n",
    "            print(\"Data not loaded or missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcb61a1",
   "metadata": {},
   "source": [
    "**Viewing the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a0f608ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US | Newyork Socioeconomic First 3 Rows:\n",
      "   report_id        reported_datetime        GEOID      reported_datetime.1  median_income  total_population  average_age\n",
      "0   64526847  2025-04-01T23:59:26.000  36081097204  2025-04-01T23:59:26.000        73207.0            4218.0         43.7\n",
      "1   64525572  2025-04-01T23:58:49.000  36047039500  2025-04-01T23:58:49.000        52188.0            3676.0         31.5\n",
      "2   64525039  2025-04-01T23:58:38.000  36005008300  2025-04-01T23:58:38.000        50920.0            6564.0         34.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for country in city_dfs:\n",
    "    for city in city_dfs[country]:\n",
    "        df = city_dfs[country][city].get(\"socioeconomic\")\n",
    "        print(f\"{country.upper()} | {city.capitalize()} Socioeconomic First 3 Rows:\")\n",
    "        if df is not None:\n",
    "            print(df.head(3))\n",
    "        else:\n",
    "            print(\"Data not loaded or missing.\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123b101d",
   "metadata": {},
   "source": [
    "**Summary of Key Stats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "11c4c836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "US | Newyork Socioeconomic Describe (Selected Columns):\n",
      "       median_income  total_population    average_age\n",
      "count  869392.000000     881846.000000  875311.000000\n",
      "mean    78785.041608       4651.341462      37.631507\n",
      "std     43335.877511       2199.175880       6.171763\n",
      "min     11406.000000          0.000000      12.600000\n",
      "25%     46645.000000       3171.000000      33.900000\n",
      "50%     71250.000000       4396.000000      36.700000\n",
      "75%     98269.000000       5774.000000      40.700000\n",
      "max    250001.000000      15945.000000      82.900000\n"
     ]
    }
   ],
   "source": [
    "columns_to_describe = [\"median_income\", \"total_population\", \"average_age\"]\n",
    "for country in city_dfs:\n",
    "    for city in city_dfs[country]:\n",
    "        df = city_dfs[country][city].get(\"socioeconomic\")\n",
    "        if df is not None:\n",
    "            cols = [col for col in columns_to_describe if col in df.columns]\n",
    "            if cols:\n",
    "                print(f\"\\n{country.upper()} | {city.capitalize()} Socioeconomic Describe (Selected Columns):\")\n",
    "                print(df[cols].describe(include='all'))\n",
    "            else:\n",
    "                print(f\"\\n{country.upper()} | {city.capitalize()} Socioeconomic: None of the selected columns found\")\n",
    "        else:\n",
    "            print(f\"\\n{country.upper()} | {city.capitalize()} Socioeconomic: Data not loaded or missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8001d1ac",
   "metadata": {},
   "source": [
    "# 1.3 **Cleaning the Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ece4132",
   "metadata": {},
   "source": [
    "### 1.3.1 **Aggregating the Weather Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5677968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_weather_df(df_weather):\n",
    "    if df_weather is None:\n",
    "        return None\n",
    "\n",
    "    # Drop weather_datetime\n",
    "    df_weather = df_weather.drop(columns=[\"weather_datetime\"], errors=\"ignore\")\n",
    "\n",
    "    # Get first issue_datetime per id\n",
    "    issue_times = df_weather.groupby(\"report_id\", as_index=False)[\"reported_datetime\"].first()\n",
    "\n",
    "    # Average other numeric columns\n",
    "    df_avg = df_weather.drop(columns=[\"reported_datetime\"]).groupby(\"report_id\", as_index=False).mean(numeric_only=True)\n",
    "\n",
    "    # Merge back issue_datetime\n",
    "    df_aggregated = pd.merge(issue_times, df_avg, on=\"report_id\")\n",
    "    \n",
    "    return df_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c0316e50",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: issue_datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[106], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m df_weather \u001b[38;5;241m=\u001b[39m city_dfs[country][city]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweather\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df_weather \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m----> 5\u001b[0m     df_weather_agg \u001b[38;5;241m=\u001b[39m \u001b[43maggregate_weather_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_weather\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     city_dfs[country][city][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweather_agg\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_weather_agg\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcountry\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcity\u001b[38;5;241m.\u001b[39mcapitalize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Weather aggregated with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_weather_agg\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Access it via: city_dfs[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcountry\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m][\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcity\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m][\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweather_agg\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m].\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[105], line 9\u001b[0m, in \u001b[0;36maggregate_weather_df\u001b[1;34m(df_weather)\u001b[0m\n\u001b[0;32m      6\u001b[0m df_weather \u001b[38;5;241m=\u001b[39m df_weather\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweather_datetime\u001b[39m\u001b[38;5;124m\"\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Get first issue_datetime per id\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m issue_times \u001b[38;5;241m=\u001b[39m \u001b[43mdf_weather\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreport_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43missue_datetime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mfirst()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Average other numeric columns\u001b[39;00m\n\u001b[0;32m     12\u001b[0m df_avg \u001b[38;5;241m=\u001b[39m df_weather\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124missue_datetime\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m, as_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Fleming Siow\\Documents\\GitHub\\HuaLaoWei\\ai_models\\chatbot\\venv\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:1951\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1945\u001b[0m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[0;32m   1946\u001b[0m     \u001b[38;5;66;03m# valid syntax, so don't raise\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1948\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot subset columns with a tuple with more than one element. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1949\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1950\u001b[0m     )\n\u001b[1;32m-> 1951\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Fleming Siow\\Documents\\GitHub\\HuaLaoWei\\ai_models\\chatbot\\venv\\Lib\\site-packages\\pandas\\core\\base.py:244\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[1;32m--> 244\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    245\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj[key]\u001b[38;5;241m.\u001b[39mndim\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gotitem(key, ndim\u001b[38;5;241m=\u001b[39mndim)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Column not found: issue_datetime'"
     ]
    }
   ],
   "source": [
    "for country in city_dfs:\n",
    "    for city in city_dfs[country]:\n",
    "        df_weather = city_dfs[country][city].get(\"weather\")\n",
    "        if df_weather is not None:\n",
    "            df_weather_agg = aggregate_weather_df(df_weather)\n",
    "            city_dfs[country][city][\"weather_agg\"] = df_weather_agg\n",
    "            print(f\"{country.upper()} - {city.capitalize()}: Weather aggregated with shape {df_weather_agg.shape}. Access it via: city_dfs['{country}']['{city}']['weather_agg'].\")\n",
    "        else:\n",
    "            print(f\"{country.upper()} - {city.capitalize()}: Weather data missing or not loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304bb9ff",
   "metadata": {},
   "source": [
    "### 1.3.2 **Schema Unification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "7a699a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = {\n",
    "    \"chicago\": {\n",
    "        \"sr_number\": \"id\",\n",
    "        \"created_date\": \"reported_datetime\",\n",
    "        \"closed_date\": \"closed_datetime\",\n",
    "        \"status\": \"status\",\n",
    "        \"latitude\": \"latitude\",\n",
    "        \"longitude\": \"longitude\",\n",
    "        \"sr_type\": \"issue_type\"\n",
    "    },\n",
    "    \"sanfrancisco\": {\n",
    "        \"service_request_id\": \"id\",\n",
    "        \"requested_datetime\": \"reported_datetime\",\n",
    "        \"closed_date\": \"closed_datetime\",\n",
    "        \"status_notes\": \"status\",\n",
    "        \"lat\": \"latitude\",\n",
    "        \"long\": \"longitude\",\n",
    "        \"service_name\": \"issue_type\"\n",
    "    },\n",
    "    \"newyork\": {\n",
    "        \"unique_key\": \"id\",\n",
    "        \"created_date\": \"reported_datetime\",\n",
    "        \"closed_date\": \"closed_datetime\",\n",
    "        \"status\": \"status\",\n",
    "        \"latitude\": \"latitude\",\n",
    "        \"longitude\": \"longitude\",\n",
    "        \"complaint_type\": \"issue_type\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "72327689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US - Chicago: Municipal schema unified. Access it via: city_dfs['us']['chicago']['municipal_unified'].\n",
      "US - Sanfrancisco: Municipal schema unified. Access it via: city_dfs['us']['sanfrancisco']['municipal_unified'].\n",
      "US - Newyork: Municipal schema unified. Access it via: city_dfs['us']['newyork']['municipal_unified'].\n"
     ]
    }
   ],
   "source": [
    "for country in city_dfs:\n",
    "    for city in city_dfs[country]:\n",
    "        city_key = city.lower()\n",
    "        df = city_dfs[country][city].get(\"municipal\")\n",
    "\n",
    "        if df is not None and city_key in column_mapping:\n",
    "            renamed_df = df.rename(columns=column_mapping[city_key])\n",
    "            city_dfs[country][city][\"municipal_unified\"] = renamed_df\n",
    "            print(f\"{country.upper()} - {city.capitalize()}: Municipal schema unified. Access it via: city_dfs['{country}']['{city}']['municipal_unified'].\")\n",
    "        else:\n",
    "            print(f\"{country.upper()} - {city.capitalize()}: No municipal data or no column mapping defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8ebe07",
   "metadata": {},
   "source": [
    "### 1.3.3 **Remove Unnecessary Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "83cc5a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_columns(df, keep_columns):\n",
    "    \"\"\"\n",
    "    Keep only the specified columns from a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: Pandas DataFrame to filter\n",
    "    - keep_columns: List of column names to retain\n",
    "\n",
    "    Returns:\n",
    "    - Filtered DataFrame\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        return None\n",
    "\n",
    "    # Keep only columns that exist in the DataFrame\n",
    "    valid_columns = [col for col in keep_columns if col in df.columns]\n",
    "    return df[valid_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "22771f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = {\n",
    "    \"municipal_unified\": [\"id\", \"status\", \"reported_datetime\", \"closed_datetime\", \"issue_type\", \"latitude\", \"longitude\"],\n",
    "    \"weather_agg\": [\"id\", \"temp_c\", \"humidity\", \"wind_kph\", \"precip_mm\", \"pm10\", \"pm2_5\", \"co\", \"no2\", \"o3\", \"so2\"],\n",
    "    \"geospatial\": [\"id\", \"commercial_count_within_200m\", \"dist_to_nearest_commericial\", \"recreation_count_within_200m\", \"dist_to_nearest_recreation\", \"facilities_count_within_200m\", \"dist_to_nearest_facility\", \"transit_count_within_200m\", \"dist_to_nearest_transit\"],\n",
    "    \"socioeconomic\": [\"id\", \"boundary_name\", \"area_km2\", \"median_income\", \"total_population\", \"average_age\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0b3253d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US - Chicago - municipal_unified: Filtered to columns. Access it via: city_dfs['us']['chicago']['municipal_unified_filtered'].\n",
      "US - Chicago - weather_agg: Filtered to columns. Access it via: city_dfs['us']['chicago']['weather_agg_filtered'].\n",
      "US - Chicago - geospatial: Filtered to columns. Access it via: city_dfs['us']['chicago']['geospatial_filtered'].\n",
      "US - Chicago - socioeconomic: Filtered to columns. Access it via: city_dfs['us']['chicago']['socioeconomic_filtered'].\n",
      "US - Sanfrancisco - municipal_unified: Filtered to columns. Access it via: city_dfs['us']['sanfrancisco']['municipal_unified_filtered'].\n",
      "US - Sanfrancisco - weather_agg: Filtered to columns. Access it via: city_dfs['us']['sanfrancisco']['weather_agg_filtered'].\n",
      "US - Sanfrancisco - geospatial: Filtered to columns. Access it via: city_dfs['us']['sanfrancisco']['geospatial_filtered'].\n",
      "US - Sanfrancisco - socioeconomic: Filtered to columns. Access it via: city_dfs['us']['sanfrancisco']['socioeconomic_filtered'].\n",
      "US - Newyork - municipal_unified: Filtered to columns. Access it via: city_dfs['us']['newyork']['municipal_unified_filtered'].\n",
      "US - Newyork - weather_agg: Filtered to columns. Access it via: city_dfs['us']['newyork']['weather_agg_filtered'].\n",
      "US - Newyork - geospatial: Filtered to columns. Access it via: city_dfs['us']['newyork']['geospatial_filtered'].\n",
      "US - Newyork - socioeconomic: Filtered to columns. Access it via: city_dfs['us']['newyork']['socioeconomic_filtered'].\n"
     ]
    }
   ],
   "source": [
    "for country in city_dfs:\n",
    "    for city in city_dfs[country]:\n",
    "        for category, keep_cols in columns_to_keep.items():\n",
    "            df = city_dfs[country][city].get(category)\n",
    "            if df is not None:\n",
    "                filtered_df = filter_columns(df, keep_cols)\n",
    "                filtered_key = f\"{category}_filtered\"\n",
    "                city_dfs[country][city][filtered_key] = filtered_df\n",
    "                # print(f\"{country.upper()} - {city.capitalize()} - {category}: Filtered to columns {filtered_df.columns.tolist()}. Access it via: city_dfs['{country}']['{city}']['{category}_filtered'].\")\n",
    "                print(f\"{country.upper()} - {city.capitalize()} - {category}: Filtered to columns. Access it via: city_dfs['{country}']['{city}']['{category}_filtered'].\")\n",
    "            else:\n",
    "                print(f\"{country.upper()} - {city.capitalize()} - {category}: Not loaded or missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36359c0",
   "metadata": {},
   "source": [
    "### 1.3.4 **Remove Bad or Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "4f26e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe(df, additional_bad_values=None):\n",
    "    \"\"\"\n",
    "    Remove rows with missing or bad values.\n",
    "\n",
    "    Parameters:\n",
    "    - df: Pandas DataFrame to clean\n",
    "    - additional_bad_values: List of extra values to treat as missing (e.g., [\"NA\", \"?\", \"-\"])\n",
    "\n",
    "    Returns:\n",
    "    - Cleaned DataFrame\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        return None\n",
    "\n",
    "    # Replace known bad values with NA\n",
    "    if additional_bad_values:\n",
    "        df = df.replace(additional_bad_values, pd.NA)\n",
    "\n",
    "    # Drop rows with any missing values\n",
    "    df_cleaned = df.dropna(how=\"any\").reset_index(drop=True)\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "15be968b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US - Chicago - municipal_unified_filtered: Cleaned shape (80988, 7). Access it via: city_dfs['us']['chicago']['municipal_unified_filtered_clean'].\n",
      "US - Chicago - weather_agg_filtered: Cleaned shape (3364, 11). Access it via: city_dfs['us']['chicago']['weather_agg_filtered_clean'].\n",
      "US - Chicago - geospatial_filtered: Cleaned shape (99852, 9). Access it via: city_dfs['us']['chicago']['geospatial_filtered_clean'].\n",
      "US - Chicago - socioeconomic_filtered: Cleaned shape (99852, 6). Access it via: city_dfs['us']['chicago']['socioeconomic_filtered_clean'].\n",
      "US - Sanfrancisco - municipal_unified_filtered: Cleaned shape (87177, 7). Access it via: city_dfs['us']['sanfrancisco']['municipal_unified_filtered_clean'].\n",
      "US - Sanfrancisco - weather_agg_filtered: Cleaned shape (3493, 11). Access it via: city_dfs['us']['sanfrancisco']['weather_agg_filtered_clean'].\n",
      "US - Sanfrancisco - geospatial_filtered: Cleaned shape (98314, 9). Access it via: city_dfs['us']['sanfrancisco']['geospatial_filtered_clean'].\n",
      "US - Sanfrancisco - socioeconomic_filtered: Cleaned shape (98293, 6). Access it via: city_dfs['us']['sanfrancisco']['socioeconomic_filtered_clean'].\n",
      "US - Newyork - municipal_unified_filtered: Cleaned shape (76027, 7). Access it via: city_dfs['us']['newyork']['municipal_unified_filtered_clean'].\n",
      "US - Newyork - weather_agg_filtered: Cleaned shape (9802, 11). Access it via: city_dfs['us']['newyork']['weather_agg_filtered_clean'].\n",
      "US - Newyork - geospatial_filtered: Cleaned shape (98350, 9). Access it via: city_dfs['us']['newyork']['geospatial_filtered_clean'].\n",
      "US - Newyork - socioeconomic_filtered: Cleaned shape (98344, 6). Access it via: city_dfs['us']['newyork']['socioeconomic_filtered_clean'].\n"
     ]
    }
   ],
   "source": [
    "categories = [\"municipal_unified_filtered\", \"weather_agg_filtered\", \"geospatial_filtered\", \"socioeconomic_filtered\"]\n",
    "\n",
    "for country in city_dfs:\n",
    "    for city in city_dfs[country]:\n",
    "        for category in categories:\n",
    "            df = city_dfs[country][city].get(category)\n",
    "            if df is not None:\n",
    "                cleaned_df = clean_dataframe(df, additional_bad_values=[\"NA\", \"?\", \"-\", \"null\", \"N/A\", \"\"])\n",
    "                clean_key = f\"{category}_clean\"\n",
    "                city_dfs[country][city][clean_key] = cleaned_df\n",
    "                print(f\"{country.upper()} - {city.capitalize()} - {category}: Cleaned shape {cleaned_df.shape}. Access it via: city_dfs['{country}']['{city}']['{category}_clean'].\")\n",
    "            else:\n",
    "                print(f\"{country.upper()} - {city.capitalize()} - {category}: Not loaded or missing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a877a40",
   "metadata": {},
   "source": [
    "### 1.3.5 **Combining and Merging Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "083533c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "municipal_combined: Combined shape = (244192, 9). Access it via: combined_by_category['municipal_combined'].\n",
      "weather_combined: Combined shape = (16659, 13). Access it via: combined_by_category['weather_combined'].\n",
      "geospatial_combined: Combined shape = (296516, 11). Access it via: combined_by_category['geospatial_combined'].\n",
      "socioeconomic_combined: Combined shape = (296489, 8). Access it via: combined_by_category['socioeconomic_combined'].\n"
     ]
    }
   ],
   "source": [
    "combined_by_category = {}\n",
    "target_categories = [\"municipal_unified_filtered_clean\", \"weather_agg_filtered_clean\", \"geospatial_filtered_clean\", \"socioeconomic_filtered_clean\"]\n",
    "\n",
    "for category in target_categories:\n",
    "    base_name = category.split(\"_\")[0]  # Get 'municipal', 'weather', etc.\n",
    "    combined_key = f\"{base_name}_combined\"\n",
    "\n",
    "    frames = []\n",
    "    for country in city_dfs:\n",
    "        for city in city_dfs[country]:\n",
    "            df = city_dfs[country][city].get(category)\n",
    "            if df is not None:\n",
    "                df = df.copy()\n",
    "                df[\"city\"] = city\n",
    "                df[\"country\"] = country\n",
    "                frames.append(df)\n",
    "\n",
    "    if frames:\n",
    "        combined_by_category[combined_key] = pd.concat(frames, ignore_index=True)\n",
    "        print(f\"{combined_key}: Combined shape = {combined_by_category[combined_key].shape}. Access it via: combined_by_category['{base_name}_combined'].\")\n",
    "    else:\n",
    "        print(f\"{combined_key}: No valid data found to combine.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ef8fa0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged with weather_combined: Result shape = (10115, 19)\n",
      "Merged with geospatial_combined: Result shape = (10115, 27)\n",
      "Merged with socioeconomic_combined: Result shape = (10115, 32)\n"
     ]
    }
   ],
   "source": [
    "# Keep city and country only from municipal_combined\n",
    "combined_by_category[\"weather_combined\"] = combined_by_category[\"weather_combined\"].drop(columns=[\"city\", \"country\"], errors=\"ignore\")\n",
    "combined_by_category[\"geospatial_combined\"] = combined_by_category[\"geospatial_combined\"].drop(columns=[\"city\", \"country\"], errors=\"ignore\")\n",
    "combined_by_category[\"socioeconomic_combined\"] = combined_by_category[\"socioeconomic_combined\"].drop(columns=[\"city\", \"country\"], errors=\"ignore\")\n",
    "\n",
    "# Start with municipal\n",
    "df_merged = combined_by_category.get(\"municipal_combined\")\n",
    "\n",
    "# Sequentially merge with the rest\n",
    "for category in [\"weather_combined\", \"geospatial_combined\", \"socioeconomic_combined\"]:\n",
    "    df_to_merge = combined_by_category.get(category)\n",
    "    if df_to_merge is not None:\n",
    "        df_merged = df_merged.merge(df_to_merge, on=\"id\", how=\"inner\", suffixes=('', f'_{category}'))\n",
    "        print(f\"Merged with {category}: Result shape = {df_merged.shape}\")\n",
    "    else:\n",
    "        print(f\"{category}: Skipped (not available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfe36b4",
   "metadata": {},
   "source": [
    "### 1.3.6 **Datatype Correction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "431af291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enforce_column_dtypes(df, dtype_mapping):\n",
    "    \"\"\"\n",
    "    Convert specified columns to desired data types if not already correct.\n",
    "\n",
    "    Parameters:\n",
    "    - df: The pandas DataFrame to modify.\n",
    "    - dtype_mapping: A dictionary in the form {\"col_name\": desired_dtype}\n",
    "\n",
    "    Returns:\n",
    "    - Modified DataFrame with columns converted as needed.\n",
    "    \"\"\"\n",
    "    for col, desired_type in dtype_mapping.items():\n",
    "        if col not in df.columns:\n",
    "            print(f\"Column '{col}' not found. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        current_type = df[col].dtype\n",
    "\n",
    "        # If already correct dtype, skip\n",
    "        if pd.api.types.is_dtype_equal(current_type, desired_type):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            if desired_type == \"datetime\":\n",
    "                df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "            else:\n",
    "                df[col] = df[col].astype(desired_type)\n",
    "            print(f\"Converted column '{col}' from {current_type} to {desired_type}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to convert column '{col}' from {current_type} to {desired_type}: {e}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "667ab7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted column 'reported_datetime' from object to datetime.\n",
      "Converted column 'closed_datetime' from object to datetime.\n",
      "Converted column 'id' from object to str.\n",
      "Converted column 'status' from object to str.\n",
      "Converted column 'total_population' from float64 to int.\n"
     ]
    }
   ],
   "source": [
    "# Define the expected dtypes\n",
    "dtype_mapping = {\n",
    "    \"reported_datetime\": \"datetime\",\n",
    "    \"closed_datetime\": \"datetime\",\n",
    "    \"id\": \"str\",\n",
    "    \"status\": \"str\",\n",
    "    \"latitude\": \"float\",\n",
    "    \"longitude\": \"float\",\n",
    "    \"median_income\": \"float\",\n",
    "    \"total_population\": \"int\",\n",
    "    \"average_age\": \"float\"\n",
    "}\n",
    "\n",
    "# Apply the function\n",
    "df_merged = enforce_column_dtypes(df_merged, dtype_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb86f1c",
   "metadata": {},
   "source": [
    "# 1.4 **Data Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadd17b6",
   "metadata": {},
   "source": [
    "### 1.4.1 **Retrieving Holiday Dates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "b2d0ae6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# U.S. holidays per relevant state\n",
    "us_holidays = {\n",
    "    \"chicago\": holidays.US(state=\"IL\"),  # Illinois\n",
    "    \"sanfrancisco\": holidays.US(state=\"CA\"),  # California\n",
    "    \"newyork\": holidays.US(state=\"NY\")  # New York\n",
    "}\n",
    "\n",
    "# Add public holiday flag\n",
    "def make_holiday_checker(date_col, city_col):\n",
    "    def check_us_holiday(row):\n",
    "        date = row[date_col].date()\n",
    "        city = row[city_col]\n",
    "        return date in us_holidays.get(city, [])\n",
    "    return check_us_holiday\n",
    "\n",
    "holiday_checker = make_holiday_checker(\"reported_datetime\", \"city\")\n",
    "df_merged[\"is_public_holiday\"] = df_merged.apply(holiday_checker, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6354d42c",
   "metadata": {},
   "source": [
    "### 1.4.2 **Standardise Issue Types into SG Categories**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3def8656",
   "metadata": {},
   "source": [
    "**Normalise Issue Types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "d9e923ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_issue(issue):\n",
    "    issue = issue.lower().strip()\n",
    "    issue = re.sub(r'[\\-\\/]', ' ', issue)  # Replace dashes/slashes with spaces\n",
    "    issue = re.sub(r'\\s+', ' ', issue)  # Collapse multiple spaces\n",
    "    return issue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f052872",
   "metadata": {},
   "source": [
    "**Keyword Mapping Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "760cd8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original mapping dictionary\n",
    "issue_type_mapping = {\n",
    "    \"Illegal Parking\": [\n",
    "        \"illegal parking\",\n",
    "        \"blocked driveway\",\n",
    "        \"parking enforcement\",\n",
    "        \"parking violation\",\n",
    "        \"parking offence\",\n",
    "        \"vehicle obstruction\",\n",
    "        \"roadside parking\"\n",
    "    ],\n",
    "    \"Facilities in HDB Estates\": [\n",
    "        \"street light pole damage\",\n",
    "        \"damaged street sign\",\n",
    "        \"sign repair request\",\n",
    "        \"sign repair request - stop sign\",\n",
    "        \"sign repair request - one way sign\",\n",
    "        \"sign repair request - do not enter sign\",\n",
    "        \"noise - residential\",\n",
    "        \"noise - house of worship\",\n",
    "        \"noise - commercial\",\n",
    "        \"noise - aircraft\",\n",
    "        \"elevator\",\n",
    "        \"boilers\",\n",
    "        \"paint/plaster\",\n",
    "        \"flooring/stairs\",\n",
    "        \"general request\",\n",
    "        \"electrical\",\n",
    "        \"plumbing\"\n",
    "    ],\n",
    "    \"Roads & Footprints\": [\n",
    "        \"street condition\",\n",
    "        \"blocked street\",\n",
    "        \"sidewalk cleaning\",\n",
    "        \"blocked sidewalk\",\n",
    "        \"alley sewer\",\n",
    "        \"traffic signal\",\n",
    "        \"street and sidewalk cleaning\",\n",
    "        \"traffic\",\n",
    "        \"obstruction\",\n",
    "        \"noise - vehicle\"\n",
    "    ],\n",
    "    \"Cleanliness\": [\n",
    "        \"dirty condition\",\n",
    "        \"litter\",\n",
    "        \"litter basket complaint\",\n",
    "        \"litter receptacle maintenance\",\n",
    "        \"street cleaning\",\n",
    "        \"graffiti\",\n",
    "        \"graffiti public\",\n",
    "        \"graffiti private\",\n",
    "        \"illegal dumping\",\n",
    "        \"residential disposal\",\n",
    "        \"commercial disposal\",\n",
    "        \"sanitation code violation\",\n",
    "        \"posting advertisement\",\n",
    "        \"illegal postings\",\n",
    "        \"unsanitary condition\",\n",
    "        \"missed collection\",\n",
    "        \"panhandling\",\n",
    "        \"residential disposal complaint\",\n",
    "        \"commercial disposal complaint\",\n",
    "        \"posting advertisement\",\n",
    "        \"missed collection\",\n",
    "        \"sanitation code violation\"\n",
    "    ],\n",
    "    \"Pests\": [\n",
    "        \"rodent\",\n",
    "        \"rat\",\n",
    "        \"vicious animal\",\n",
    "        \"animal-abuse\"\n",
    "    ],\n",
    "    \"Animals & Bird\": [\n",
    "        \"animal complaint\",\n",
    "        \"dead animal\",\n",
    "        \"animal in a park\",\n",
    "        \"report an injured animal\",\n",
    "        \"stray dog\",\n",
    "        \"wildlife\",\n",
    "        \"violation of park rules\"\n",
    "    ],\n",
    "    \"Smoking\": [\n",
    "        \"illegal smoking\",\n",
    "        \"smoking offence\",\n",
    "        \"urinating in public\",\n",
    "        \"drinking\",\n",
    "        \"drug activity\"\n",
    "    ],\n",
    "    \"Parks & Greenery\": [\n",
    "        \"tree emergency\",\n",
    "        \"tree debris\",\n",
    "        \"fallen tree\",\n",
    "        \"park maintenance\",\n",
    "        \"animal in a park\",\n",
    "        \"violation of park rules\",\n",
    "        \"noise - park\"\n",
    "    ],\n",
    "    \"Drains & Sewers\": [\n",
    "        \"sewer\",\n",
    "        \"clogged drain\",\n",
    "        \"flood\",\n",
    "        \"water on street\",\n",
    "        \"water in basement\",\n",
    "        \"check for leak\",\n",
    "        \"sewer cleaning\",\n",
    "        \"alley sewer inspection\"\n",
    "    ],\n",
    "    \"Drinking Water\": [\n",
    "        \"check for leak\",\n",
    "        \"water system\",\n",
    "        \"water quality\",\n",
    "        \"hydrant issue\"\n",
    "    ],\n",
    "    \"Construction Sites\": [\n",
    "        \"construction noise\",\n",
    "        \"general construction\",\n",
    "        \"building/use\",\n",
    "        \"illegal construction\",\n",
    "        \"real time enforcement\",\n",
    "        \"special projects inspection team\",\n",
    "        \"general construction/plumbing\"\n",
    "    ],\n",
    "    \"Abandoned Trolleys\": [\n",
    "        \"abandoned cart\",\n",
    "        \"abandoned vehicle\",\n",
    "        \"abandoned vehicle complaint\",\n",
    "        \"derelict vehicles\"\n",
    "    ],\n",
    "    \"Shared Bicycles\": [\n",
    "        \"bike blocking path\",\n",
    "        \"divvy bike parking complaint\",\n",
    "        \"e-scooter parking complaint\",\n",
    "        \"bike/roller/skate chronic\"\n",
    "    ],\n",
    "    \"Others\": [\n",
    "        \"311 information only call\",\n",
    "        \"emergency response team\",\n",
    "        \"encampment\",\n",
    "        \"homeless person assistance\",\n",
    "        \"vendor enforcement\",\n",
    "        \"institution disposal complaint\",\n",
    "        \"muni employee feedback\",\n",
    "        \"disorderly youth\",\n",
    "        \"electrical\",\n",
    "        \"emergency response team (ert)\",\n",
    "        \"special projects inspection team (spit)\",\n",
    "        \"general\",\n",
    "        \"real time enforcement\"\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a83eadc",
   "metadata": {},
   "source": [
    "**Flashtext Processor Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "ea01f6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up flashtext for fast keyword lookup\n",
    "keyword_processor = KeywordProcessor()\n",
    "for category, keywords in issue_type_mapping.items():\n",
    "    for keyword in keywords:\n",
    "        keyword_processor.add_keyword(keyword.lower(), category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284d5b13",
   "metadata": {},
   "source": [
    "**Fuzzy Matching**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "db895cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_match_category(issue, threshold=80):\n",
    "    issue = str(issue).lower()\n",
    "    best_match = (\"Others\", 0)\n",
    "    for category, keywords in issue_type_mapping.items():\n",
    "        for keyword in keywords:\n",
    "            score = fuzz.partial_ratio(issue, keyword)\n",
    "            if score > best_match[1]:\n",
    "                best_match = (category, score)\n",
    "    return best_match[0] if best_match[1] >= threshold else \"Others\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b204ad",
   "metadata": {},
   "source": [
    "**GPT-4 LLM Categorisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae26f313",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))  # $env:OPENAI_API_KEY = \"api-key-here\"\n",
    "\n",
    "# Store GPT results to avoid repeated API calls\n",
    "gpt_cache = {}\n",
    "\n",
    "def gpt_fallback_category(issue):\n",
    "    issue = str(issue).strip().lower()\n",
    "    \n",
    "    if issue in gpt_cache:\n",
    "        return gpt_cache[issue]\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Categorise the following municipal issue into one of these Singapore categories:\n",
    "    {list(issue_type_mapping.keys())}.\n",
    "    Issue: \"{issue}\"\n",
    "    Category:\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0\n",
    "        )\n",
    "        result = response.choices[0].message.content.strip()\n",
    "        # Remove any surrounding quotes or labels like \"Category: 'Cleanliness'\"\n",
    "        result = re.sub(r'[\"“”‘’\\']', '', result).strip()\n",
    "        result = result.replace(\"Category:\", \"\").strip()\n",
    "        gpt_cache[issue] = result\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"OpenAI API Error: {e}\")\n",
    "        return \"Others\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3c74e4",
   "metadata": {},
   "source": [
    "**Hybrid Issue Matching Setup & Execution**   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "92cffd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_category_label(label):\n",
    "    label = label.strip()\n",
    "    label = re.sub(r\"^[\\\"'‘’“”]+|[\\\"'‘’“”]+$\", \"\", label)  # Strip leading/trailing quotes\n",
    "    return label\n",
    "\n",
    "def map_to_sg_category_hybrid(issue):\n",
    "    issue = normalize_issue(issue)\n",
    "    \n",
    "    # FlashText fast match\n",
    "    matches = keyword_processor.extract_keywords(issue)\n",
    "    if matches:\n",
    "        return matches[0]\n",
    "\n",
    "    # Fuzzy fallback\n",
    "    fuzzy_result = fuzzy_match_category(issue)\n",
    "    if fuzzy_result != \"Others\":\n",
    "        return fuzzy_result\n",
    "\n",
    "    # GPT fallback\n",
    "    return gpt_fallback_category(issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "90ff7647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cache from file if it exists\n",
    "cache_path = \"cache/gpt_cache.json\"\n",
    "if os.path.exists(cache_path):\n",
    "    with open(cache_path, \"r\") as f:\n",
    "        gpt_cache = json.load(f)\n",
    "else:\n",
    "    gpt_cache = {}\n",
    "\n",
    "# Save cache to file after processing\n",
    "def save_cache():\n",
    "    with open(cache_path, \"w\") as f:\n",
    "        json.dump(gpt_cache, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "fa51c38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[\"issue_type_sg\"] = df_merged[\"issue_type\"].apply(map_to_sg_category_hybrid).apply(clean_category_label)\n",
    "save_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "52fdccbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped SG Issue Types:\n",
      "issue_type_sg\n",
      "Illegal Parking              2757\n",
      "Others                       2535\n",
      "Facilities in HDB Estates    2142\n",
      "Roads & Footprints           1966\n",
      "Cleanliness                   227\n",
      "Abandoned Trolleys            134\n",
      "Smoking                        93\n",
      "Construction Sites             72\n",
      "Parks & Greenery               64\n",
      "Pests                          41\n",
      "Drains & Sewers                40\n",
      "Drinking Water                 25\n",
      "Shared Bicycles                12\n",
      "Animals & Bird                  7\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Quick check\n",
    "print(\"Mapped SG Issue Types:\")\n",
    "print(df_merged[\"issue_type_sg\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7346fbb5",
   "metadata": {},
   "source": [
    "# 1.5 **Final Check & Saving**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d863f2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to intermediate file for EDA\n",
    "df_merged.to_csv(\"../data/files/cleaned_reports.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
