services:
  inference:
    image: vlm:latest
    ports:
      - '8080:8080'
    environment:
      - HF_HOME=/app/cache/huggingface
    volumes:
      - model_weights:/app/cache/huggingface

volumes:
  model_weights:
