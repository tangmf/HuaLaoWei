{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8866801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Gradio and required LangChain packages\n",
    "# !pip install -U PyPDF2 gradio langchain langchain-community langchain-core langchain-huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e297ea",
   "metadata": {},
   "source": [
    "**Imports and Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "294b58a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.runnables import Runnable\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from PyPDF2 import PdfReader\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import cv2\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f144539b",
   "metadata": {},
   "source": [
    "**Load Embeddings and VectorStores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fec78bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "faiss_docs = FAISS.load_local(\n",
    "    folder_path=\"../vectorstores/faiss_index_multimodal/faiss_docs\",\n",
    "    embeddings=embedding_model,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "faiss_images = FAISS.load_local(\n",
    "    folder_path=\"../vectorstores/faiss_index_multimodal/faiss_images\",\n",
    "    embeddings=embedding_model,\n",
    "    allow_dangerous_deserialization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d29802",
   "metadata": {},
   "source": [
    "**Define the RAG Chain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c5e1e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM(model=\"deepseek-r1:7b\")  # Can switch to another Ollama-compatible LLM\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "        You are an assistant for municipal issue queries in Singapore.\n",
    "\n",
    "        Answer the question below using only the provided context.\n",
    "        If possible, in your reply, provide the user as much details as possible.\n",
    "        If unsure, say \"I don't know\".\n",
    "\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        Question:\n",
    "        {question}\n",
    "\n",
    "        Format your reply starting with \"**Answer:**\" followed by your clear response.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain: Runnable = (\n",
    "    {\n",
    "        \"context\": lambda q: format_docs(faiss_docs.similarity_search(q, k=5) + faiss_images.similarity_search(q, k=3)),\n",
    "        \"question\": lambda q: q\n",
    "    }\n",
    "    | prompt_template\n",
    "    | llm\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3752ba5f",
   "metadata": {},
   "source": [
    "**File Upload Processing (PDF/Image)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8caf578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(path):\n",
    "    try:\n",
    "        reader = PdfReader(path)\n",
    "        return \"\\n\".join(page.extract_text() or \"\" for page in reader.pages)\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def extract_text_from_image(path):\n",
    "    try:\n",
    "        image = cv2.imread(path)\n",
    "        if image is None:\n",
    "            print(f\"[WARN] Failed to load image from {path}\")\n",
    "            return \"\"\n",
    "        text = pytesseract.image_to_string(image)\n",
    "        print(f\"[DEBUG] OCR result:\\n{text[:300]}\")\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] OCR failed for {path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def process_upload(file_path):\n",
    "    ext = Path(file_path).suffix.lower()\n",
    "    if ext == \".pdf\":\n",
    "        content = extract_text_from_pdf(file_path)\n",
    "    elif ext in [\".png\", \".jpg\", \".jpeg\"]:\n",
    "        content = extract_text_from_image(file_path)\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    if content:\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500,\n",
    "            chunk_overlap=50,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"]\n",
    "        )\n",
    "        chunks = text_splitter.split_text(content)\n",
    "        faiss_images.add_texts(chunks)\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c6a6f3",
   "metadata": {},
   "source": [
    "**Multimodal RAG Logic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0d46bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_final_answer(result: str) -> str:\n",
    "    if \"**Answer:**\" in result:\n",
    "        return result.split(\"**Answer:**\")[-1].strip()\n",
    "    return result.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcec0a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from pathlib import Path\n",
    "\n",
    "def run_multimodal_rag(message=None, file=None, chat_history=None):\n",
    "    query = message.strip() if message else \"\"\n",
    "    file_text = \"\"\n",
    "\n",
    "    if file and isinstance(file, str) and Path(file).exists():\n",
    "        ext = Path(file).suffix.lower()\n",
    "        try:\n",
    "            if ext == \".pdf\":\n",
    "                file_text = extract_text_from_pdf(file)\n",
    "            elif ext in [\".png\", \".jpg\", \".jpeg\"]:\n",
    "                file_text = extract_text_from_image(file)\n",
    "        except Exception as e:\n",
    "            file_text = f\"[ERROR] Cannot extract text: {e}\"\n",
    "\n",
    "        if file_text.strip():\n",
    "            query += f\"\\n\\n[Context from uploaded file]:\\n{file_text.strip()}\"\n",
    "\n",
    "    if not query.strip():\n",
    "        return [chat_history, \"\", chat_history]\n",
    "\n",
    "    try:\n",
    "        # Assume `rag_chain.invoke(query)` gives us the assistant's reply\n",
    "        result = rag_chain.invoke(query)\n",
    "        reply = extract_final_answer(result)\n",
    "        chat_history = chat_history or []\n",
    "        chat_history.append({\"role\": \"user\", \"content\": message})\n",
    "        chat_history.append({\"role\": \"assistant\", \"content\": reply})\n",
    "        return [chat_history, \"\", chat_history]\n",
    "    except Exception as e:\n",
    "        chat_history.append({\"role\": \"user\", \"content\": message})\n",
    "        chat_history.append({\"role\": \"assistant\", \"content\": \"Error: \" + str(e)})\n",
    "        return [chat_history, \"\", chat_history]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316c1a80",
   "metadata": {},
   "source": [
    "**Gradio UI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "945b4dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Users\\Fleming Siow\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41f2790c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] OCR result:\n",
      "HOUSING &\n",
      "DEVELOPMENT\n",
      "BOARD\n",
      "\n",
      "INDEMNITY FORM\n",
      "(RENOVATION)\n",
      "\n",
      "HDB Branch\n",
      "\n",
      "RENOVATIONS TO BE CARRIED OUT AT APT BLK\n",
      "\n",
      "In consideration of your agreeing at my/our request fo grant a renovation permitto carry out renovations.\n",
      "specified in the renovation permit at Apt Bik .\n",
      "vwe NAIC and.\n",
      "\n",
      "NAIC the proposed p\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(height=400, show_copy_button=True, type=\"messages\")\n",
    "    state = gr.State([])  # Stores chat history\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=4):\n",
    "            txt = gr.Textbox(\n",
    "                placeholder=\"Ask something like: 'What are the rules for displaying banners in Clementi?'\",\n",
    "                show_label=False\n",
    "            )\n",
    "        with gr.Column(scale=1):\n",
    "            upload = gr.File(\n",
    "                file_types=[\".pdf\", \".png\", \".jpg\", \".jpeg\"],\n",
    "                file_count=\"single\",\n",
    "                type=\"filepath\",\n",
    "                label=\"Upload a document or image\"\n",
    "            )\n",
    "\n",
    "    btn = gr.Button(\"Send\")\n",
    "\n",
    "    btn.click(\n",
    "        run_multimodal_rag,\n",
    "        inputs=[txt, upload, state],\n",
    "        outputs=[chatbot, txt, state],\n",
    "        api_name=\"chat\"\n",
    "    )\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
