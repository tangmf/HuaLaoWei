{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "725e3162",
   "metadata": {},
   "source": [
    "**Setup & Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c892b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import RunnableMap, RunnablePassthrough\n",
    "from langchain.vectorstores.utils import DistanceStrategy\n",
    "\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89310e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-ollama\n",
      "  Downloading langchain_ollama-0.3.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting ollama<1,>=0.4.4 (from langchain-ollama)\n",
      "  Downloading ollama-0.4.7-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in c:\\users\\fleming siow\\documents\\github\\hualaowei\\ai_models\\chatbot\\venv\\lib\\site-packages (from langchain-ollama) (0.3.51)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\fleming siow\\documents\\github\\hualaowei\\ai_models\\chatbot\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain-ollama) (0.3.30)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\fleming siow\\documents\\github\\hualaowei\\ai_models\\chatbot\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain-ollama) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\fleming siow\\documents\\github\\hualaowei\\ai_models\\chatbot\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain-ollama) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\fleming siow\\documents\\github\\hualaowei\\ai_models\\chatbot\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain-ollama) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\fleming siow\\documents\\github\\hualaowei\\ai_models\\chatbot\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain-ollama) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\fleming siow\\documents\\github\\hualaowei\\ai_models\\chatbot\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain-ollama) (4.13.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\fleming siow\\documents\\github\\hualaowei\\ai_models\\chatbot\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain-ollama) (2.11.3)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in c:\\users\\fleming siow\\documents\\github\\hualaowei\\ai_models\\chatbot\\venv\\lib\\site-packages (from ollama<1,>=0.4.4->langchain-ollama) (0.28.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\fleming siow\\documents\\github\\hualaowei\\ai_models\\chatbot\\venv\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\fleming siow\\documents\\github\\hualaowei\\ai_models\\chatbot\\venv\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\fleming siow\\documents\\github\\hualaowei\\ai_models\\chatbot\\venv\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (1.0.8)\n",
      "Requirement already satisfied: idna in c:\\users\\fleming siow\\documents\\github\\hualaowei\\ai_models\\chatbot\\venv\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\fleming siow\\documents\\github\\hualaowei\\ai_models\\chatbot\\venv\\lib\\site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\fleming siow\\documents\\github\\hualaowei\\ai_models\\chatbot\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain-ollama) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\fleming siow\\documents\\github\\hualaowei\\ai_models\\chatbot\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain-ollama) (3.10.16)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\fleming siow\\documents\\github\\hualaowei\\ai_models\\chatbot\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain-ollama) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\fleming siow\\documents\\github\\hualaowei\\ai_models\\chatbot\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain-ollama) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\fleming siow\\documents\\github\\hualaowei\\ai_models\\chatbot\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain-ollama) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\fleming siow\\documents\\github\\hualaowei\\ai_models\\chatbot\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.51->langchain-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\fleming siow\\documents\\github\\hualaowei\\ai_models\\chatbot\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.51->langchain-ollama) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\fleming siow\\documents\\github\\hualaowei\\ai_models\\chatbot\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.51->langchain-ollama) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\fleming siow\\documents\\github\\hualaowei\\ai_models\\chatbot\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain-ollama) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\fleming siow\\documents\\github\\hualaowei\\ai_models\\chatbot\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain-ollama) (2.4.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\fleming siow\\documents\\github\\hualaowei\\ai_models\\chatbot\\venv\\lib\\site-packages (from anyio->httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (1.3.1)\n",
      "Downloading langchain_ollama-0.3.1-py3-none-any.whl (20 kB)\n",
      "Downloading ollama-0.4.7-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: ollama, langchain-ollama\n",
      "Successfully installed langchain-ollama-0.3.1 ollama-0.4.7\n"
     ]
    }
   ],
   "source": [
    "# install package\n",
    "# !pip install -U langchain-ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3595904f",
   "metadata": {},
   "source": [
    "**Load Text and Image Vector Stores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5548061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded FAISS indices for documents and OCR image data.\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Load text vectorstore\n",
    "faiss_docs = FAISS.load_local(\n",
    "    folder_path=\"../vectorstores/faiss_index_multimodal/faiss_docs\",\n",
    "    embeddings=embedding_model,\n",
    "    distance_strategy=DistanceStrategy.COSINE,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "# Load image-based OCR vectorstore\n",
    "faiss_images = FAISS.load_local(\n",
    "    folder_path=\"../vectorstores/faiss_index_multimodal/faiss_images\",\n",
    "    embeddings=embedding_model,\n",
    "    distance_strategy=DistanceStrategy.COSINE,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "print(\"Loaded FAISS indices for documents and OCR image data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcc407e",
   "metadata": {},
   "source": [
    "**Combine Text + Image FAISS into a Hybrid Retriever**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "524d01a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid retriever combining text and OCR vectorstores ready.\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.vectorstores.base import VectorStoreRetriever\n",
    "\n",
    "# Wrap each vectorstore as a retriever\n",
    "text_retriever = VectorStoreRetriever(vectorstore=faiss_docs)\n",
    "image_retriever = VectorStoreRetriever(vectorstore=faiss_images)\n",
    "\n",
    "# Combine both with equal weights (can tune)\n",
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers=[text_retriever, image_retriever],\n",
    "    weights=[0.5, 0.5]  # You can tune if one is more reliable\n",
    ")\n",
    "\n",
    "print(\"Hybrid retriever combining text and OCR vectorstores ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8868909b",
   "metadata": {},
   "source": [
    "**Build the RAG Chain with DeepSeek LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7a0dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multimodal RAG chain ready for querying!\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "# Load DeepSeek model\n",
    "llm = OllamaLLM(model=\"deepseek-r1:7b\")\n",
    "\n",
    "# Final RAG chain\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",  # You can switch to refine or map_reduce for longer contexts\n",
    "    retriever=hybrid_retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "print(\"Multimodal RAG chain ready for querying!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4299f8f",
   "metadata": {},
   "source": [
    "**Try a Query**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "686fbb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fleming Siow\\AppData\\Local\\Temp\\ipykernel_1440\\3577143117.py:2: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = rag_chain(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      " <think>\n",
      "Okay, so I need to figure out how to apply for a renovation permit through HDB and what documents are needed. Let me try to go through the information provided step by step.\n",
      "\n",
      "First, it says that applications can only be made electronically via APEX on HDB InfoWEB. So, I guess I have to use this online system instead of sending something in the mail or handing it over. The user mentioned that they should log into My HDBPage under \"My Business > flat Renovation (For Contractors)\" and then apply from there. That's probably where all the necessary information is entered electronically.\n",
      "\n",
      "Now, the process seems to require two parts: Part III and IV of the form. I'm not exactly sure what these parts entail, but since it's a guide for using APEX, maybe they are specific sections or steps within the application. The user noted that this form is only applicable when APEX isn't available due to unforeseen issues. So, in normal circumstances, you should use Part III and IV of this form.\n",
      "\n",
      "Next, there's something about home owners authorizing their contractors for renovation work needing HDB's prior approval. That means the contractor needs to get a signed acknowledgement from all the flat owners involved. The user mentioned that they can download an acknowledgment form from the specified website. So, I think each owner must sign this form and provide it once the application is submitted.\n",
      "\n",
      "Putting it all together: To apply for a renovation permit through HDB, you need to:\n",
      "1. Use APEX on HDB InfoWEB.\n",
      "2. Log into My HDBPage under \"My Business > flat Renovation (For Contractors)\".\n",
      "3. Fill out and submit Parts III and IV of the provided form.\n",
      "\n",
      "As for documents needed, based on the information given, it seems that an acknowledgment form signed by all flat owners is required. This form can be downloaded from a specific URL mentioned in the helpful answer example.\n",
      "\n",
      "I should make sure to double-check if there are any other documents or steps I might have missed. Since APEX is electronic and only available through HDB InfoWEB, it's likely that no physical forms need to be filled out except for this acknowledgment form once submission happens.\n",
      "</think>\n",
      "\n",
      "To apply for a renovation permit from HDB via APEX on HDB InfoWEB, follow these steps:\n",
      "\n",
      "1. **Access the System**: Log into My HDBPage and navigate to \"My Business > flat Renovation (For Contractors)\".\n",
      "\n",
      "2. **Submit the Application**: Use APEX to electronically submit Parts III and IV of the provided form. These parts are part of the application guide meant for online use when APEX is accessible.\n",
      "\n",
      "3. **Prepare Necessary Documents**: Download and obtain the acknowledgment form from the specified URL. This form must be signed by all flat owners involved in the renovation work.\n",
      "\n",
      "4. **Submit Acknowledgment**: Once submitted through APEX, attach this form to your application to complete the renovation permit process.\n",
      "\n",
      "Ensure that all steps are followed correctly to avoid any delays or issues with the application.\n",
      "\n",
      "Sources:\n",
      "- unknown\n",
      "- unknown\n",
      "- unknown\n",
      "- unknown\n"
     ]
    }
   ],
   "source": [
    "query = \"How do I apply for a renovation permit from HDB? What documents do I need?\"\n",
    "response = rag_chain(query)\n",
    "\n",
    "print(\"Answer:\\n\", response[\"result\"])\n",
    "print(\"\\nSources:\")\n",
    "for doc in response[\"source_documents\"]:\n",
    "    print(\"-\", doc.metadata.get(\"source\", \"unknown\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
